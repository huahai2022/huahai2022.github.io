<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>概率扩展模型</title>
      <link href="/2023/07/25/gai-lu-kuo-zhan-mo-xing/"/>
      <url>/2023/07/25/gai-lu-kuo-zhan-mo-xing/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV1b541197HX/?spm_id_from=333.999.0.0&amp;vd_source=b176201190025ae11ffeced1d766effe">54、Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读_哔哩哔哩_bilibili</a>   B站才是我的大学，🙁</p><p><img src="https://i0.hdslb.com/bfs/new_dyn/a180978fc2337febe001ab17001a6a27373596439.jpg@1048w_!web-dynamic.webp" alt="img"></p><p>Diffusion model是一种新的最先进的生成模型，可以生成多样化的高分辨率图像。在OpenAI、Nvidia和Google成功训练大型模型后，它们已经引起了很多关注。基于扩散模型的示例架构包括GLIDE、DALLE-2、Imagen和完整的开源stable diffusion。</p><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230726211313770.png" alt="image-20230726211313770"></p><h1 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h1><h5 id="1-Introduction-Denoising-Diffusion-Model"><a href="#1-Introduction-Denoising-Diffusion-Model" class="headerlink" title="1.Introduction(Denoising Diffusion Model)"></a>1.Introduction(Denoising Diffusion Model)</h5><p>Diffusion Models是生成模型，意味着它们用于生成与它们训练的数据类似的数据。从根本上讲，Diffusion Models通过连续添加Gaussian noise来破坏训练数据，然后学习通过反转这个加noising的过程来恢复数据。训练后，我们可以通过将随机抽样的noise通过学习得到的denoising过程来生成数据。</p><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230726211913551.png" alt="image-20230726211913551"></p><p>GAN和VAE是两种重要的生成模型，在多个应用中都取得了很大的成功和认可。GAN表现出色，但是由于多种挑战（例如mode collapse和vanishing gradients等），其输出缺乏多样性，且很难训练。VAE有最稳固的理论基础，但是在VAE中建模良好的损失函数是一个挑战，这使得它们的输出是次优的。</p><p>Diffusion Modeling的关键概念在于，如果我们能够建立一个学习模型，能够学习由于噪声而导致的信息系统性衰减，那么就应该能够反转这个过程，从噪声中恢复信息。这个概念与VAE相似，它尝试通过首先将数据投影到潜在空间，然后将其恢复到初始状态来优化目标函数。然而，系统的目标不是学习数据分布，而是在Markov链中建模一系列噪声分布，并通过分层方式来解码数据，从而撤消/消除数据中的噪声。<img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230726213728259.png" alt="image-20230726213728259"></p><p>Diffusion model可以被看作是latent variable model。latent variable意味着我们是指一个隐藏的连续特征空间。这样，它们可能看起来类似于variational autoencoders (VAEs)。</p><p>有几种基于扩散的生成模型提出了类似的想法，包括diffusion probabilistic models（Sohl-Dickstein et al.，2015年），noise-conditioned score network（NCSN; Yang＆Ermon，2019年）和denoising diffusion probabilistic models（DDPM; Ho等人，2020年）。</p><p>在实践中，Diffusion model使用了T步的Markov链来建模。这里，Markov链意味着每一步只依赖于前一步，这是一个温和的假设。重要的是，与 flow-based models不同，我们不受限于使用特定类型的神经网络。</p><p>更具体地说，Diffusion Model是一种潜在变量模型，使用固定的Markov链将数据映射到潜在空间。该链逐渐添加噪声到数据中，以获得近似后验q(x1:T | x0)分布，其中x1,….XT是具有相同维度的潜在变量。在下面的图中，我们看到了用于图像数据的这样的Markov链的表现。</p><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230726214006809.png" alt="image-20230726214006809"></p><h5 id="2-Forward-diffusion-process"><a href="#2-Forward-diffusion-process" class="headerlink" title="2.Forward diffusion process"></a>2.Forward diffusion process</h5><h5 id="3-Reverse-diffusion-process"><a href="#3-Reverse-diffusion-process" class="headerlink" title="3.Reverse diffusion process"></a>3.Reverse diffusion process</h5><h5 id="4-Architecture"><a href="#4-Architecture" class="headerlink" title="4.Architecture"></a>4.Architecture</h5><h5 id="5-Training-and-sampling-algorithms"><a href="#5-Training-and-sampling-algorithms" class="headerlink" title="5.Training and sampling algorithms"></a>5.Training and sampling algorithms</h5><h5 id="6-Conditioned-Generation"><a href="#6-Conditioned-Generation" class="headerlink" title="6.Conditioned Generation"></a>6.Conditioned Generation</h5><h5 id="7-Stable-diffusion-Latent-diffusion-model"><a href="#7-Stable-diffusion-Latent-diffusion-model" class="headerlink" title="7.Stable diffusion: Latent diffusion model"></a>7.Stable diffusion: Latent diffusion model</h5><h5 id="8-Summary"><a href="#8-Summary" class="headerlink" title="8.Summary"></a>8.Summary</h5>]]></content>
      
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多维向量的乘积</title>
      <link href="/2023/07/19/duo-wei-xiang-liang-de-cheng-ji/"/>
      <url>/2023/07/19/duo-wei-xiang-liang-de-cheng-ji/</url>
      
        <content type="html"><![CDATA[<p>shape=[2,2,3]的三维矩阵，可以视为2个shape=[2,3]的二维矩阵堆叠在一起！！最后两维才是有数据的矩阵，前面的维度只是矩阵的排列而已！</p><p>所以在矩阵运算的时候，其实最后都可以转成我们常见的二维矩阵运算，遵循的原则是：在多维矩阵相乘中，需最后两维满足shape匹配原则，最后两维才是有数据的矩阵，前面的维度只是矩阵的排列而已！</p><p>比如说是一个输入[64,3,32,32]，第一维度表示batch_size，第二维度表示通道数。</p><pre class="line-numbers language-none"><code class="language-none">a = [[[ 1.  2.  3.]  [ 4.  5.  6.]] [[ 7.  8.  9.]  [10. 11. 12.]]]b = [[[ 1.  2.]  [ 3.  4.]  [ 5.  6.]] [[ 7.  8.]  [ 9. 10.]  [11. 12.]]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230719132230670.png" alt="image-20230719132230670"></p><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230719132230670.png"></p><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230719132259087.png" alt="image-20230719132259087"></p>]]></content>
      
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>百度AI</title>
      <link href="/2023/07/17/bai-du-ai/"/>
      <url>/2023/07/17/bai-du-ai/</url>
      
        <content type="html"><![CDATA[<p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230717090749273.png" alt="image-20230717090749273"></p><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230722075209939.png" alt="image-20230722075209939"></p>]]></content>
      
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java中的数据结构</title>
      <link href="/2023/07/15/java-zhong-de-shu-ju-jie-gou/"/>
      <url>/2023/07/15/java-zhong-de-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<h5 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h5><ul><li>List，Set，Map都是接口，前两个继承Collection接口，Map为独立的接口。</li><li>Set下面有HashSet,LinkedHashSet,TreeSet</li><li>List下面有ArrayList,Vector,LinkedList</li><li>Map下面有Hashtable,LinkedHashMap,HashMap,TreeMap</li><li>Collection接口下面还有个Queue接口，有PriorityQueue类</li></ul><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230715155010903.png" alt="image-20230715155010903"></p><ul><li>LinkedList既可以实现Queue接口,也可以实现List接口.只不过呢, LinkedList实现了Queue接口。Queue接口窄化了对LinkedList的方法的访问权限（即在方法中的参数类型如果是Queue时，就完全只能访问Queue接口所定义的方法 了，而不能直接访问 LinkedList的非Queue的方法），以使得只有恰当的方法才可以使用。</li></ul><h5 id="List有序，可重复"><a href="#List有序，可重复" class="headerlink" title="List有序，可重复"></a>List有序，可重复</h5><p>ArrayList优点：底层数据结构是数组，查询快，增删慢。缺点线程不安全，效率高。</p><p>Vector优点：底层是数组，查询快，增删慢。缺点线程安全，效率低。</p><p>LinkedList优点：底层是链表，查询慢，增删快。缺点线程不安全，效率高。</p><h5 id="Set无序，唯一"><a href="#Set无序，唯一" class="headerlink" title="Set无序，唯一"></a>Set无序，唯一</h5><p>HashSet:底层数据结构是哈希表(无序，唯一)。如何保证元素唯一性？依赖两个方法：hashCode()和equals()。主要用来排序。</p><p>LinkedHashSet:底层数据结构是链表和哈希表。(FIFO插入有序，唯一)由链表保证元素有序，由哈希表保证元素唯一。主要用来保证FIFO有序的集合。</p><p>TreeSet:底层数据结构是红黑树。(唯一，有序）1.如何保证元素排序：自然排序，比较器排序。2.如何保证元素唯一性：根据比较的返回值是否是0来决定。通用的存储数据的集合。</p><pre class="line-numbers language-none"><code class="language-none">唯一吗?是：Set排序吗?是：TreeSet或LinkedHashSet否：HashSet如果你知道是Set，但是不知道是哪个Set，就用HashSet。否：List要安全吗?是：Vector否：ArrayList或者LinkedList查询多：ArrayList增删多：LinkedList如果你知道是List，但是不知道是哪个List，就用ArrayList。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="Map接口"><a href="#Map接口" class="headerlink" title="Map接口"></a>Map接口</h5><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230715161752563.png" alt="image-20230715161752563"></p><p>Map接口实现了三个重要的类，分别是HashMap、TreeMap和HashTable</p><ul><li>TreeMap是有序的，HashMap和HashTable是无序的。</li><li>Hashtable的方法是同步的，HashMap的方法不是同步的，这是两者最主要的区别。</li></ul><p>这就意味着：</p><ul><li><p>hashtable是线程安全的，HashMap不是线程安全的。</p></li><li><p>HashMap效率较高，HashTable效率较低。</p><p>如果对同步性或与遗留代码的兼容性没有任何要求，建议使用HashMap。 查看Hashtable的源代码就可以发现，除构造函数外，Hashtable的所有 public 方法声明中都有 synchronized关键字，而HashMap的源码中则没有。</p></li><li><p>Hashtable不允许null值，HashMap允许null值（key和value都允许）</p></li><li><p>父类不同：Hashtable的父类是Dictionary，HashMap的父类是AbstractMap</p></li></ul><h5 id="TreeSet的排序"><a href="#TreeSet的排序" class="headerlink" title="TreeSet的排序"></a>TreeSet的排序</h5><pre class="line-numbers language-none"><code class="language-none">1.基本数据类型可以直接排序2.引用数据类型可以使用自然排序和比较器排序2.1自然排序：例如Student类中实现Comparable接口，重写Comparable接口中的Compareto方法public class Student implements Comparable&lt;Student&gt;{private String name;private int age;public int compareTo(Student s){int num=this.name.length()-s.name.length();int num1=num==0?this.name.compareTo(s.name):num;int num2=num1==0?this.age-s.age:num1;return num2;}}2.2比较器排序：单独创建一个比较类，这里以MyComparator为例，并且要让他继承Comparator接口；重写Comparator接口中的Compare接口。public class MyComparator implements Comparator&lt;Student&gt;{public int compare(Student s1,Student s2){int num=s1.getName().length()-s2.getName().length();int num1=num==0?s1.getName().compareTo(s2.getName()):num;int num2=num1==0?s1.getAge()-s2.getAge():num2;}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode</title>
      <link href="/2023/07/15/leetcode/"/>
      <url>/2023/07/15/leetcode/</url>
      
        <content type="html"><![CDATA[<h5 id="leetcode1362-最接近的因数"><a href="#leetcode1362-最接近的因数" class="headerlink" title="leetcode1362.最接近的因数"></a>leetcode1362.最接近的因数</h5><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230715104042344.png" alt="image-20230715104042344"></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">closestDivisors</span><span class="token punctuation">(</span><span class="token keyword">int</span> num<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> divisor<span class="token operator">=</span>num<span class="token operator">==</span><span class="token number">1</span><span class="token operator">?</span>num<span class="token operator">+</span><span class="token number">1</span><span class="token operator">:</span>num<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">sqrt</span><span class="token punctuation">(</span>divisor<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>divisor<span class="token operator">&gt;</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            i<span class="token operator">--</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>divisor<span class="token operator">/</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">def</span> <span class="token function">closestDivisor</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>        divisor <span class="token operator">=</span> num <span class="token operator">+</span> <span class="token number">1</span> <span class="token keyword">if</span> num <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> num <span class="token operator">+</span> <span class="token number">2</span>        i<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>divisor<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">while</span> divisor <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>    i <span class="token operator">-=</span> <span class="token number">1</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>i<span class="token punctuation">,</span>divisor<span class="token operator">/</span>i<span class="token punctuation">]</span><span class="token comment">#上一个好一点</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">closestDivisors</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">#------------------中心开花----------------</span>        <span class="token keyword">def</span> <span class="token function">calc</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>num <span class="token operator">**</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> num <span class="token operator">%</span> x <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> <span class="token punctuation">[</span>x<span class="token punctuation">,</span> num <span class="token operator">//</span> x<span class="token punctuation">]</span>        res1 <span class="token operator">=</span> calc<span class="token punctuation">(</span>num <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>        res2 <span class="token operator">=</span> calc<span class="token punctuation">(</span>num <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> res1 <span class="token keyword">if</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>res1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span>res1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>res2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span>res2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">else</span> res2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">package mainimport (    "fmt"    "math")func closestDivisors(num int) []int {    divisor := num + 1    if num == 1 {        divisor = num + 1    } else {        divisor = num + 2    }    i := int(math.Sqrt(float64(divisor)))    for divisor%i &gt; 1 {        i--    }    return []int{i, divisor / i}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h5><pre class="line-numbers language-none"><code class="language-none">二叉搜索树（Binary Search Tree，BST）是一种基于二叉树的数据结构。它具有以下性质：1. 对于任意一个节点，它的左子树中的所有节点的值都小于该节点的值。2. 对于任意一个节点，它的右子树中的所有节点的值都大于该节点的值。3. 左右子树也分别为二叉搜索树。因此，二叉搜索树中的节点按照从小到大的顺序排列。它支持插入、删除和查找操作，它们的时间复杂度都是 O(log n)。在一些特殊情况下，二叉搜索树的高度可能会退化为链表，这时候操作的时间复杂度会退化为 O(n)。二叉搜索树可以用来实现一些高效的算法，如二叉搜索、二叉排序树、AVL树、红黑树等。它也被广泛应用于数据库、搜索引擎、文件系统等领域。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="leetcode108"><a href="#leetcode108" class="headerlink" title="leetcode108"></a>leetcode108</h5><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230715142725906.png" alt="image-20230715142725906"></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token class-name">TreeNode</span> <span class="token function">sortedArrayToVST</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token function">helper</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>nums<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">TreeNode</span> <span class="token function">helper</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>nums<span class="token punctuation">,</span><span class="token keyword">int</span> left<span class="token punctuation">,</span><span class="token keyword">int</span> right<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>left<span class="token operator">&gt;</span>right<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">int</span> mid<span class="token operator">=</span><span class="token punctuation">(</span>left<span class="token operator">+</span>right<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span>        <span class="token class-name">TreeNode</span> root<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">TreeNode</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        root<span class="token punctuation">.</span>left<span class="token operator">=</span><span class="token function">helper</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span>left<span class="token punctuation">,</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        root<span class="token punctuation">.</span>right<span class="token operator">=</span><span class="token function">helper</span><span class="token punctuation">(</span>nums<span class="token punctuation">.</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> root<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Definition for a binary tree node.</span><span class="token comment"># class TreeNode:</span><span class="token comment">#     def __init__(self, val=0, left=None, right=None):</span><span class="token comment">#         self.val = val</span><span class="token comment">#         self.left = left</span><span class="token comment">#         self.right = right</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">sortedArrayToBST</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>nums<span class="token punctuation">:</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token operator">&gt;</span>TreeNode<span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">helper</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> left<span class="token operator">&gt;</span>right<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">None</span>           mid<span class="token operator">=</span><span class="token punctuation">(</span>left<span class="token operator">+</span>right<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            root<span class="token operator">=</span>TreeNode<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span>            root<span class="token punctuation">.</span>left<span class="token operator">=</span>helper<span class="token punctuation">(</span>left<span class="token punctuation">,</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            root<span class="token punctuation">.</span>right<span class="token operator">=</span>helper<span class="token punctuation">(</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>right<span class="token punctuation">)</span>            <span class="token keyword">return</span> root        <span class="token keyword">return</span> helper<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token comment">/** * Definition for a binary tree node. * type TreeNode struct { *     Val int *     Left *TreeNode *     Right *TreeNode * } */</span><span class="token keyword">func</span> <span class="token function">sortedArrayToBST</span><span class="token punctuation">(</span>nums <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">*</span>TreeNode <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token function">helper</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token function">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">helper</span><span class="token punctuation">(</span>nums <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">,</span>left <span class="token builtin">int</span><span class="token punctuation">,</span>right <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">*</span>TreeNode<span class="token punctuation">{</span>    <span class="token keyword">if</span> left<span class="token operator">&gt;</span>right<span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span>    <span class="token punctuation">}</span>    mid<span class="token operator">:=</span><span class="token punctuation">(</span>left<span class="token operator">+</span>right<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span>    root<span class="token operator">:=</span><span class="token operator">&amp;</span>TreeNode<span class="token punctuation">{</span>Val<span class="token punctuation">:</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">}</span>    root<span class="token punctuation">.</span>Left<span class="token operator">=</span><span class="token function">helper</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span>left<span class="token punctuation">,</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    root<span class="token punctuation">.</span>Right<span class="token operator">=</span><span class="token function">helper</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>right<span class="token punctuation">)</span>    <span class="token keyword">return</span> root<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="leetcode1382"><a href="#leetcode1382" class="headerlink" title="leetcode1382"></a>leetcode1382</h5><p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230715151610608.png" alt="image-20230715151610608"></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/** * Definition for a binary tree node. * public class TreeNode { *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode() {} *     TreeNode(int val) { this.val = val; } *     TreeNode(int val, TreeNode left, TreeNode right) { *         this.val = val; *         this.left = left; *         this.right = right; *     } * } */</span><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token punctuation">{</span>    <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> inorderSeq<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">TreeNode</span> <span class="token function">balanceBST</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> root<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token function">getInorder</span><span class="token punctuation">(</span>root<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token function">build</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>inorderSeq<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">getInorder</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> tree<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>left<span class="token operator">!=</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token function">getInorder</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>left<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        inorderSeq<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>right<span class="token operator">!=</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token function">getInorder</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>right<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">TreeNode</span> <span class="token function">build</span><span class="token punctuation">(</span><span class="token keyword">int</span> l<span class="token punctuation">,</span><span class="token keyword">int</span> r<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> mid<span class="token operator">=</span><span class="token punctuation">(</span>l<span class="token operator">+</span>r<span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token class-name">TreeNode</span> root<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">TreeNode</span><span class="token punctuation">(</span>inorderSeq<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>mid<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>l<span class="token operator">&lt;=</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            root<span class="token punctuation">.</span>left<span class="token operator">=</span><span class="token function">build</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token operator">&lt;=</span>r<span class="token punctuation">)</span><span class="token punctuation">{</span>            root<span class="token punctuation">.</span>right<span class="token operator">=</span><span class="token function">build</span><span class="token punctuation">(</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>r<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> root<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Definition for a binary tree node.</span><span class="token comment"># class TreeNode:</span><span class="token comment">#     def __init__(self, val=0, left=None, right=None):</span><span class="token comment">#         self.val = val</span><span class="token comment">#         self.left = left</span><span class="token comment">#         self.right = right</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">inOrder</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>root<span class="token punctuation">,</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> root<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>        self<span class="token punctuation">.</span>inOrder<span class="token punctuation">(</span>root<span class="token punctuation">.</span>left<span class="token punctuation">,</span>nums<span class="token punctuation">)</span>        nums<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root<span class="token punctuation">.</span>val<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>inOrder<span class="token punctuation">(</span>root<span class="token punctuation">.</span>right<span class="token punctuation">,</span>nums<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>nums<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> left<span class="token operator">&gt;</span>right<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">None</span>        mid<span class="token operator">=</span><span class="token punctuation">(</span>left<span class="token operator">+</span>right<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        root<span class="token operator">=</span>TreeNode<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span>        root<span class="token punctuation">.</span>left<span class="token operator">=</span>self<span class="token punctuation">.</span>process<span class="token punctuation">(</span>nums<span class="token punctuation">,</span>left<span class="token punctuation">,</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        root<span class="token punctuation">.</span>right<span class="token operator">=</span>self<span class="token punctuation">.</span>process<span class="token punctuation">(</span>nums<span class="token punctuation">,</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>right<span class="token punctuation">)</span>        <span class="token keyword">return</span> root    <span class="token keyword">def</span> <span class="token function">balanceBST</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">:</span> TreeNode<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> TreeNode<span class="token punctuation">:</span>        nums<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>inOrder<span class="token punctuation">(</span>root<span class="token punctuation">,</span>nums<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>process<span class="token punctuation">(</span>nums<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token comment">/** * Definition for a binary tree node. * type TreeNode struct { *     Val int *     Left *TreeNode *     Right *TreeNode * } */</span><span class="token keyword">func</span> <span class="token function">balanceBST</span><span class="token punctuation">(</span>root <span class="token operator">*</span>TreeNode<span class="token punctuation">)</span> <span class="token operator">*</span>TreeNode <span class="token punctuation">{</span>    nums<span class="token operator">:=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">var</span> inorder <span class="token keyword">func</span><span class="token punctuation">(</span>node <span class="token operator">*</span>TreeNode<span class="token punctuation">)</span>    inorder <span class="token operator">=</span><span class="token keyword">func</span><span class="token punctuation">(</span>node <span class="token operator">*</span>TreeNode<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span> node<span class="token operator">==</span><span class="token boolean">nil</span><span class="token punctuation">{</span>            <span class="token keyword">return</span>        <span class="token punctuation">}</span>        <span class="token function">inorder</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>Left<span class="token punctuation">)</span>        nums<span class="token operator">=</span><span class="token function">append</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span>node<span class="token punctuation">.</span>Val<span class="token punctuation">)</span>        <span class="token function">inorder</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>Right<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token function">inorder</span><span class="token punctuation">(</span>root<span class="token punctuation">)</span>    <span class="token keyword">var</span> buildTree <span class="token keyword">func</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span>r <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">*</span>TreeNode    buildTree<span class="token operator">=</span><span class="token keyword">func</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span>r <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">*</span>TreeNode<span class="token punctuation">{</span>        mid<span class="token operator">:=</span><span class="token punctuation">(</span>l<span class="token operator">+</span>r<span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token number">1</span>        node<span class="token operator">:=</span><span class="token operator">&amp;</span>TreeNode<span class="token punctuation">{</span>Val<span class="token punctuation">:</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">}</span>        <span class="token keyword">if</span> l<span class="token operator">&lt;=</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">{</span>            node<span class="token punctuation">.</span>Left<span class="token operator">=</span><span class="token function">buildTree</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span>mid<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> r<span class="token operator">&gt;=</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">{</span>            node<span class="token punctuation">.</span>Right<span class="token operator">=</span><span class="token function">buildTree</span><span class="token punctuation">(</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>r<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> node    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token function">buildTree</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token function">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java" data-language="java"><code class="language-java">#<span class="token constant">AVL</span>旋转平衡二叉树旋转的情况一共有<span class="token number">4</span>种情况：新加入节点为 node<span class="token punctuation">.</span>left 的左孩子， <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span> 。直接对node节点右旋。新加入节点为 node<span class="token punctuation">.</span>left 的右孩子， <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span> 。这时候要先对node<span class="token punctuation">.</span>left左旋，调整为<span class="token number">1</span>的情况，再进行右旋。新加入节点为 node<span class="token punctuation">.</span>right 的右孩子， <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span> 。直接对node节点左旋。新加入节点为 node<span class="token punctuation">.</span>right 的左孩子， <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token function">height</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span> 。这时候要先对node<span class="token punctuation">.</span>right右旋，调整为<span class="token number">3</span>的情况，再进行左旋。<span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token class-name">TreeNode</span> <span class="token function">balanceBST</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> root<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>root<span class="token operator">==</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TreeNode</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> nodeHeight<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token class-name">TreeNode</span> newRoot<span class="token operator">=</span><span class="token keyword">null</span><span class="token punctuation">;</span>        <span class="token class-name">Deque</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TreeNode</span><span class="token punctuation">&gt;</span></span> stack<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">LinkedList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token class-name">TreeNode</span> node<span class="token operator">=</span>root<span class="token punctuation">;</span>        <span class="token comment">//先序遍历,利用栈很巧妙</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>node<span class="token operator">!=</span><span class="token keyword">null</span><span class="token operator">||</span><span class="token operator">!</span>stack<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>node<span class="token operator">!=</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                newRoot<span class="token operator">=</span><span class="token function">insert</span><span class="token punctuation">(</span>newRoot<span class="token punctuation">,</span>node<span class="token punctuation">.</span>val<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>                stack<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span>node<span class="token punctuation">)</span><span class="token punctuation">;</span>                node<span class="token operator">=</span>node<span class="token punctuation">.</span>left<span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">else</span><span class="token punctuation">{</span>                node<span class="token operator">=</span>stack<span class="token punctuation">.</span><span class="token function">pop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                node<span class="token operator">=</span>node<span class="token punctuation">.</span>right<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> newRoot<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token class-name">TreeNode</span> <span class="token function">insert</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> root<span class="token punctuation">,</span><span class="token keyword">int</span> val<span class="token punctuation">,</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TreeNode</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> nodeHeight<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>root<span class="token operator">==</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            root<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">TreeNode</span><span class="token punctuation">(</span>val<span class="token punctuation">)</span><span class="token punctuation">;</span>            nodeHeight<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>root<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> root<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token class-name">TreeNode</span> node<span class="token operator">=</span>root<span class="token punctuation">;</span>        <span class="token keyword">int</span> cmp<span class="token operator">=</span>val<span class="token operator">-</span>node<span class="token punctuation">.</span>val<span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>cmp<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token comment">//左子树插入</span>            node<span class="token punctuation">.</span>left<span class="token operator">=</span><span class="token function">insert</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>left<span class="token punctuation">,</span>val<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">-</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>val<span class="token operator">&gt;</span>node<span class="token punctuation">.</span>left<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">{</span>                    node<span class="token punctuation">.</span>left<span class="token operator">=</span><span class="token function">rotateLeft</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>                node<span class="token operator">=</span><span class="token function">rotateLeft</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>cmp<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            node<span class="token punctuation">.</span>right<span class="token operator">=</span><span class="token function">insert</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>right<span class="token punctuation">,</span>val<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">-</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>val<span class="token operator">&lt;</span>node<span class="token punctuation">.</span>right<span class="token punctuation">.</span>val<span class="token punctuation">)</span><span class="token punctuation">{</span>                node<span class="token punctuation">.</span>right<span class="token operator">=</span><span class="token function">rotateRight</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">,</span><span class="token class-name">NodeHeight</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            node<span class="token operator">=</span><span class="token function">rotateLeft</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> node<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">int</span> height<span class="token operator">=</span><span class="token function">getCurNodeNewHeight</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>    nodeHeight<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>height<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> node<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token class-name">TreeNode</span> <span class="token function">rotateLeft</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> node<span class="token punctuation">,</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TreeNode</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> nodeHeight<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token class-name">TreeNode</span> right<span class="token operator">=</span>node<span class="token punctuation">.</span>right<span class="token punctuation">;</span>    node<span class="token punctuation">.</span>right<span class="token operator">=</span>right<span class="token punctuation">.</span>left<span class="token punctuation">;</span>    right<span class="token punctuation">.</span>left<span class="token operator">=</span>node<span class="token punctuation">;</span>    <span class="token keyword">int</span> newNodeHeight<span class="token operator">=</span><span class="token function">getCurNodeNewHeight</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>    nodeHeight<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>newNodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> newRightHeight<span class="token operator">=</span><span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>newNodeHeight<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>right<span class="token punctuation">.</span>right<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span>    nodeHeight<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>right<span class="token punctuation">,</span>newRightHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> right<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token class-name">TreeNode</span> <span class="token function">rotateRight</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> node<span class="token punctuation">,</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TreeNode</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> nodeHeight<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token comment">// ---指针调整</span>        <span class="token class-name">TreeNode</span> left <span class="token operator">=</span> node<span class="token punctuation">.</span>left<span class="token punctuation">;</span>        node<span class="token punctuation">.</span>left <span class="token operator">=</span> left<span class="token punctuation">.</span>right<span class="token punctuation">;</span>        left<span class="token punctuation">.</span>right <span class="token operator">=</span> node<span class="token punctuation">;</span>        <span class="token comment">// ---高度更新</span>        <span class="token comment">// 先更新node节点的高度，这个时候node是right节点的左孩子</span>        <span class="token keyword">int</span> newNodeHeight <span class="token operator">=</span> <span class="token function">getCurNodeNewHeight</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">// 更新node节点高度</span>        nodeHeight<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span>newNodeHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">// newNodeHeight是现在left节点右子树高度，原理一样，取现在right左右子树最大高度+1</span>        <span class="token keyword">int</span> newLeftHeight <span class="token operator">=</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>newNodeHeight<span class="token punctuation">,</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>left<span class="token punctuation">.</span>left<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token comment">// 更新原left节点高度</span>        nodeHeight<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span>newLeftHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> left<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment">/**     * 获取当前节点的新高度     * @param node node     * @param nodeHeight node高度缓存     * @return 当前node的新高度     */</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> <span class="token function">getCurNodeNewHeight</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span> node<span class="token punctuation">,</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TreeNode</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> nodeHeight<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token comment">// node节点的高度，为现在node左右子树最大高度+1</span>        <span class="token keyword">return</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>left<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nodeHeight<span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span>right<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>左旋转<img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230716112659587.png" alt="image-20230716112659587"></p><p>右旋转<img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230716112722681.png" alt="image-20230716112722681"></p><p>双旋转<img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230716112751501.png" alt="image-20230716112751501"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLM实现本地知识库问答项目中的一些笔记</title>
      <link href="/2023/07/10/llm-shi-xian-ben-di-zhi-shi-ku-wen-da-xiang-mu-zhong-de-yi-xie-bi-ji/"/>
      <url>/2023/07/10/llm-shi-xian-ben-di-zhi-shi-ku-wen-da-xiang-mu-zhong-de-yi-xie-bi-ji/</url>
      
        <content type="html"><![CDATA[<p><img src="https://dradon.oss-cn-hangzhou.aliyuncs.com/img/image-20230620085336168.png" alt="image-20230620085336168"></p><h5 id="AutoModel-from-pretrained"><a href="#AutoModel-from-pretrained" class="headerlink" title="AutoModel.from_pretrained()"></a>AutoModel.from_pretrained()</h5><pre class="line-numbers language-text" data-language="text"><code class="language-text">AuroModel.from_pretrained()是Hugging Face Transformers库中用于加载预训练模型的方法。它可以从本地文件、Hugging Face Hub、URL等多种来源加载预训练模型，并返回一个模型对象，用于后续的预测和训练。具体来说，AutoModel.from_pretrained()方法的参数如下：- `checkpoint`：必需参数，表示要加载的模型的名称、路径或URL。- `config`：可选参数，表示要使用的模型配置。如果未指定，会根据模型名称自动选择一个默认的配置文件。- `torch_dtype`：可选参数，表示要使用的PyTorch张量数据类型。默认为`torch.float32`，也可以设置为`torch.float16`或`torch.bfloat16`。- `trust_remote_code`：可选参数，表示是否信任从远程源加载的代码（如Hugging Face Hub）。默认为`False`，也可以设置为`True`。- `cache_dir`：可选参数，表示要使用的缓存目录。如果未指定，会使用默认的缓存目录（`~/.cache/huggingface/transformers`）。- `force_download`：可选参数，表示是否强制重新下载模型。默认为`False`，也可以设置为`True`。- `resume_download`：可选参数，表示是否从上次下载的位置恢复下载。默认为`False`，也可以设置为`True`。- `proxies`：可选参数，表示要使用的代理设置。默认为`None`，也可以设置为代理URL字符串或代理字典。- `local_files_only`：可选参数，表示是否只从本地文件加载模型。默认为`False`，也可以设置为`True`。在这段代码中，`LoaderClass.from_pretrained()`方法的第一个参数是`checkpoint`，表示要加载的模型的名称、路径或URL。第二个参数是`config`，表示要使用的模型配置，这里使用了已经加载好的`self.model_config`。第三个参数`torch_dtype`表示要使用的PyTorch张量数据类型，这里根据`self.bf16`的值选择了`torch.bfloat16`或`torch.float16`。第四个参数`trust_remote_code`表示是否信任从远程源（如Hugging Face Hub）加载的代码，这里设置为`True`。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="torch-dfloat16和torch-float16"><a href="#torch-dfloat16和torch-float16" class="headerlink" title="torch.dfloat16和torch.float16"></a>torch.dfloat16和torch.float16</h5><pre class="line-numbers language-text" data-language="text"><code class="language-text">`torch.bfloat16`和`torch.float16`是PyTorch张量的两种不同数据类型，它们在存储精度和内存占用方面有所不同。具体来说，`torch.bfloat16`是一种16位浮点数数据类型，它可以存储更大的数值范围，但精度相对较低。这种数据类型通常用于深度神经网络的训练和推理中，可以加速运算并减少内存占用。但是，由于精度较低，可能会对模型的准确性产生一定的影响。在使用`torch.bfloat16`时，需要注意数值范围的限制，以避免数值溢出或下溢的问题。而`torch.float16`是另一种16位浮点数数据类型，它可以存储较小的数值范围，但精度相对较高。这种数据类型通常用于计算机视觉、自然语言处理等任务中，可以提高模型的准确性。但是，由于存储精度较高，内存占用和计算复杂度也相应较高。因此，选择使用哪种数据类型取决于具体的任务需求和硬件限制。在使用`torch.bfloat16`时，需要注意数值范围的限制，以避免数值溢出或下溢的问题；在使用`torch.float16`时，则需要注意内存占用和计算复杂度的问题。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="from-accelerate-import-dispatch-model的解释"><a href="#from-accelerate-import-dispatch-model的解释" class="headerlink" title="from accelerate import dispatch_model的解释"></a>from accelerate import dispatch_model的解释</h5><pre class="line-numbers language-none"><code class="language-none">`dispatch_model`是`accelerate`库中的一个函数，用于根据当前硬件环境和设置自动选择加速器，以加速模型的训练和推理。具体来说，`dispatch_model`函数会根据以下几个因素自动选择加速器：1. 硬件环境：加速器的选择会根据计算机的GPU类型、数量和性能等因素进行优化。2. PyTorch版本：加速器的选择会根据使用的PyTorch版本进行优化，以最大程度地提高性能。3. 加速器类型：根据用户设置的加速器类型（例如混合精度训练、分布式训练等），选择最佳的加速器实现。使用`dispatch_model`函数可以简化模型训练和推理的代码编写，并提高模型的训练和推理效率。具体来说，你可以将模型对象传递给`dispatch_model`函数，该函数会自动选择最佳的加速器，并返回一个已经使用加速器的模型对象。例如，下面是一个使用`dispatch_model`函数进行模型训练的示例：```from accelerate import dispatch_model# 加载预训练模型model = LoaderClass.from_pretrained(checkpoint)# 自动选择加速器model, optimizer, train_loader, valid_loader = dispatch_model(model, optimizer, train_loader, valid_loader)# 训练模型for epoch in range(num_epochs):    for batch in train_loader:        ...```在这个示例中，`dispatch_model`函数会自动选择最佳的加速器，并将加速器应用到模型、优化器和数据加载器中，从而提高模型的训练效率。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="float"><a href="#float" class="headerlink" title=".float()"></a>.float()</h5><pre class="line-numbers language-none"><code class="language-none">在PyTorch中，`.float()`是`Tensor`类的一个方法，用于将`Tensor`对象转换为浮点数类型。在模型中使用`.float()`通常用于将输入数据的数据类型转换为浮点数类型，以便于模型能够正确处理数据。这是因为在PyTorch中，模型的输入和参数通常是浮点数类型，如果输入数据的数据类型与模型期望的数据类型不一致，可能会导致模型无法正确处理数据。下面是一个示例，展示了在模型中使用`.float()`方法将输入数据转换为浮点数类型：```pythonimport torch.nn as nn# 定义一个模型class MyModel(nn.Module):    def __init__(self):        super(MyModel, self).__init__()        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)        self.fc1 = nn.Linear(16 * 6 * 6, 10)    def forward(self, x):        x = self.conv1(x)        x = x.view(-1, 16 * 6 * 6)        x = self.fc1(x)        return x# 实例化模型并将其移动到GPU上model = MyModel().cuda()# 定义一个输入数据input_data = torch.randn(1, 3, 32, 32)# 将输入数据转换为浮点数类型并将其移动到GPU上input_data = input_data.float().cuda()# 使用模型进行推理outputs = model(input_data)```在这个示例中，我们首先定义了一个`MyModel`模型，并将其移动到GPU上。然后，我们定义了一个输入数据`input_data`，并使用`.float()`方法将其转换为浮点数类型，并将其移动到GPU上。最后，我们使用模型对输入数据进行推理，并得到输出结果。通过将输入数据转换为浮点数类型，我们可以确保模型能够正确处理数据，并避免出现数据类型不匹配的错误。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="load-in-8bit的作用"><a href="#load-in-8bit的作用" class="headerlink" title="load_in_8bit的作用"></a>load_in_8bit的作用</h5><pre class="line-numbers language-none"><code class="language-none">load_in_8bit`是一个布尔类型的变量，通常用于控制数据加载时的精度。具体来说，如果`load_in_8bit`为True，则数据将以8位整数的形式加载，否则将以32位浮点数的形式加载。在机器学习中，为了提高模型训练和推理的效率，通常会采用低精度的数据表示方式，例如8位整数。这种方式可以减少数据的存储和传输开销，同时也可以加速计算过程。但是，低精度的数据表示方式可能会对模型的性能和精度产生一定的影响，因此需要根据具体的情况进行选择。在具体的实现中，`load_in_8bit`通常会作为一个参数传递给数据加载器或模型的构造函数，用于控制数据的加载精度。例如，在PyTorch中，可以通过设置`torch.utils.data.DataLoader`类的`dtype`参数来控制数据的加载精度。而在TensorFlow中，可以通过设置数据加载器的`dtype`参数或模型的`dtype`属性来控制数据的加载精度。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="模型对应的tokenizer"><a href="#模型对应的tokenizer" class="headerlink" title="模型对应的tokenizer"></a>模型对应的tokenizer</h5><pre class="line-numbers language-none"><code class="language-none">在自然语言处理任务中，文本数据需要被转换为数字才能被模型处理。这个转换过程被称为"tokenization"，它将原始文本分成一系列"token"，并将每个token映射到一个唯一的整数ID。模型接收这些整数ID作为输入，并使用它们来计算输出。在Hugging Face Transformers库中，每个模型都有一个对应的tokenizer，用于将输入文本转换为模型需要的格式。tokenizer将输入文本分成token，并将每个token映射到一个整数ID。tokenizer还可以执行其他的预处理步骤，例如截断、填充等等。if type(model) is transformers.LlamaForCausalLM:tokenizer = LlamaTokenizer.from_pretrained(checkpoint, clean_up_tokenization_spaces=True)回答你的问题，这段代码检查模型是否是`LlamaForCausalLM`类的实例。如果是，就使用`LlamaTokenizer`类的`from_pretrained`方法加载相应的tokenizer。这个tokenizer将输入文本分成token，并将每个token映射到一个整数ID，以便模型可以处理。在这个代码中，tokenizer的作用是将输入文本转换为模型需要的格式，以便模型可以计算输出。需要注意的是，不同的模型可能需要不同的tokenizer。如果使用错误的tokenizer，可能会导致模型无法正确处理输入数据。因此，在使用模型之前，需要确保使用正确的tokenizer对输入数据进行预处理。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="cls-x3D-get-class-from-dynamic-module-class-reference-x3D-”fnlp-x2F-moss-moon-003-sft–modeling-moss-MossForCausalLM”，-pretrained-model-name-or-path-x3D-checkpoint-什么意思"><a href="#cls-x3D-get-class-from-dynamic-module-class-reference-x3D-”fnlp-x2F-moss-moon-003-sft–modeling-moss-MossForCausalLM”，-pretrained-model-name-or-path-x3D-checkpoint-什么意思" class="headerlink" title="cls = get_class_from_dynamic_module(class_reference=”fnlp/moss-moon-003-sft–modeling_moss.MossForCausalLM”， pretrained_model_name_or_path=checkpoint)什么意思"></a>cls = get_class_from_dynamic_module(class_reference=”fnlp/moss-moon-003-sft–modeling_moss.MossForCausalLM”， pretrained_model_name_or_path=checkpoint)什么意思</h5><pre class="line-numbers language-none"><code class="language-none">这段代码的作用是从动态模块中获取一个类对象。具体来说，该函数接受两个参数：- `class_reference`：类的引用。在这个例子中，引用是 `fnlp/moss-moon-003-sft--modeling_moss.MossForCausalLM`，这意味着该函数将尝试从 `fnlp/moss-moon-003-sft--modeling_moss` 动态模块中获取一个名为 `MossForCausalLM` 的类。- `pretrained_model_name_or_path`：预训练模型的名称或路径。该参数用于实例化 `MossForCausalLM` 类的对象。该函数的实现可能类似于以下代码：```pythondef get_class_from_dynamic_module(class_reference,pretrained_model_name_or_path):    # 从类引用中获取模块名称和类名称    module_name, class_name = class_reference.rsplit(".", 1)    # 动态导入模块    module = importlib.import_module(module_name)    # 从模块中获取类对象    cls = getattr(module, class_name)    # 实例化对象并返回    return cls.from_pretrained(pretrained_model_name_or_path)```这个函数首先将类引用分解成模块名称和类名称。然后，它动态地导入模块，并从模块中获取类对象。最后，它使用给定的预训练模型名称或路径实例化类对象，并返回该对象。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="分析代码with-init-empty-weights"><a href="#分析代码with-init-empty-weights" class="headerlink" title="分析代码with init_empty_weights():"></a>分析代码with init_empty_weights():</h5><pre><code>model = LoaderClass.from_config(self.model_config,trust_remote_code = True)model.tie_weights()</code></pre><pre class="line-numbers language-none"><code class="language-none">这段代码的作用是使用一个空的权重初始化模型，然后将模型的权重绑定到模型中的所有共享层。这个操作通常用于加载已经训练好的模型的配置，但是不想使用它的权重。在这种情况下，我们可以使用一个空的权重初始化模型，然后将模型的权重绑定到模型中的共享层。这样做的好处是，可以在不使用已有模型的权重的情况下，使用已有模型的配置来构建一个新的模型。在这段代码中，`LoaderClass`是一个用于加载模型的类，`from_config`方法用于根据给定的配置创建一个新的模型对象，`trust_remote_code`参数设置为`True`表示信任远程代码，可以用于从远程加载模型。`tie_weights`方法用于将模型中的共享层绑定到一起，以便它们可以共享相同的权重，这样可以减少模型参数的数量，提高模型的训练效率。`with`语句是Python中的一个上下文管理器，用于管理资源的申请和释放。在这段代码中，`with init_empty_weights():`语句使用了一个自定义的上下文管理器`init_empty_weights()`，这个上下文管理器在进入上下文时执行一些操作，然后在退出上下文时再执行一些操作。在这里，`init_empty_weights()`上下文管理器的作用是用一个空的权重初始化模型，当退出上下文时，模型将被保存在`model`变量中。使用`with`语句的好处是，在退出上下文时，Python会自动调用上下文管理器的`__exit__()`方法，释放资源并执行一些清理操作。这样可以避免在代码中显式地调用资源释放和清理操作，从而使代码更加简洁和可读。同时，使用`with`语句还可以确保资源的正确释放，无论代码中是否出现了异常或错误，都可以保证资源被正确释放。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="在python中，模块和包的区别是什么"><a href="#在python中，模块和包的区别是什么" class="headerlink" title="在python中，模块和包的区别是什么"></a>在python中，模块和包的区别是什么</h5><pre class="line-numbers language-none"><code class="language-none">在Python中，模块和包都是组织代码的方式，但它们的作用和使用方式略有不同。模块是Python中的一个概念，它是一个包含Python代码的文件，通常以`.py`为扩展名。模块可以包含定义变量、函数、类和语句的代码，可以被其他模块或程序导入和使用。在Python中，可以使用`import`语句导入一个模块，并使用模块中定义的变量、函数和类等。包是Python中另一个概念，它是一个包含多个模块的目录。包通常包含一个特殊的`__init__.py`文件，用于指定包的初始化代码和导入的模块列表。在Python中，可以使用`import`语句导入一个包，也可以使用`from ... import`语句导入一个包中的模块、变量、函数和类等。因此，模块和包的区别在于：1. 模块是一个文件，包含Python代码；包是一个目录，包含多个模块和一个`__init__.py`文件。2. 模块通常包含一些特定的功能，可以被其他模块或程序导入和使用；包通常包含多个相关的模块，用于组织和管理代码。3. 在Python中，可以使用`import`语句导入一个模块或包，但是导入包时需要指定具体的模块或子包名称。需要注意的是，模块和包是Python中非常重要的概念，可以帮助我们更好地组织和管理代码。在实际编程中，应该根据需要合理地使用模块和包，以提高代码的可读性、可维护性和可重用性。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="logging文件日志"><a href="#logging文件日志" class="headerlink" title="logging文件日志"></a>logging文件日志</h5><pre class="line-numbers language-none"><code class="language-none">在 Python 中，可以使用 `logging` 模块来输出日志。该模块提供了一种灵活且可定制的方式来记录日志信息，并可以控制日志的输出级别、格式和目标等。下面是一个简单的示例，演示如何使用 `logging` 模块输出日志：```pythonimport logging# 配置日志信息logging.basicConfig(filename='example.log', level=logging.DEBUG, format='%(asctime)s %(levelname)s %(message)s')# 输出日志信息logging.debug('This is a debug message')logging.info('This is an info message')logging.warning('This is a warning message')logging.error('This is an error message')logging.critical('This is a critical message')```在上面的示例中，我们首先使用 `basicConfig()` 方法配置了日志信息，指定了日志文件的名称为 `example.log`，日志级别为 `DEBUG`，日志格式为 `%(asctime)s %(levelname)s %(message)s`。然后，我们使用 `logging` 模块的不同方法输出不同级别的日志信息。输出的日志信息将被写入到指定的日志文件中，并且根据配置的日志级别，只有等于或高于该级别的日志信息才会被输出。例如，在上面的示例中，由于指定的日志级别为 `DEBUG`，因此所有级别的日志信息都会被输出到日志文件中。当然，您还可以根据需要进一步配置日志信息，如指定日志文件的最大大小、备份数量等，以及将日志信息输出到标准输出、邮件等目标。更多关于 `logging` 模块的详细信息可以参考官方文档：https://docs.python.org/3/library/logging.html。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="向量库生成中FAISS类探究"><a href="#向量库生成中FAISS类探究" class="headerlink" title="向量库生成中FAISS类探究"></a>向量库生成中FAISS类探究</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">    <span class="token comment">#FAISS向量的初始化</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        embedding_function<span class="token punctuation">:</span> Callable<span class="token punctuation">,</span>  <span class="token comment">#一个可以调用的对象(函数或者方法)，用于将文本转化为向量</span>        index<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>       <span class="token comment">#向量索引库，用于存储向量和实现检索功能</span>        docstore<span class="token punctuation">:</span> Docstore<span class="token punctuation">,</span>   <span class="token comment">#文本存储库，用于存储原始文本和文本的元数据信息</span>        index_to_docstore_id<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token comment">#一个字典，用于将向量索引库的ID映射到文本存储库中的ID</span>        relevance_score_fn<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>             Callable<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span>        <span class="token punctuation">]</span> <span class="token operator">=</span> _default_relevance_score_fn<span class="token punctuation">,</span>    <span class="token comment">#一个可调用对象(函数或者方法)，用于计算检索结果的相关性得分(可选参数，默认为内置的相关性得分函数)</span>        normalize_L2<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>      <span class="token comment">#是否对向量进行L2归一化</span>    <span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Initialize with necessary components."""</span>        self<span class="token punctuation">.</span>embedding_function <span class="token operator">=</span> embedding_function        self<span class="token punctuation">.</span>index <span class="token operator">=</span> index        self<span class="token punctuation">.</span>docstore <span class="token operator">=</span> docstore        self<span class="token punctuation">.</span>index_to_docstore_id <span class="token operator">=</span> index_to_docstore_id        self<span class="token punctuation">.</span>relevance_score_fn <span class="token operator">=</span> relevance_score_fn        self<span class="token punctuation">.</span>_normalize_L2 <span class="token operator">=</span> normalize_L2        <span class="token comment">###index如何指定和定义</span>IndexFlatL2：基于 L2 距离度量的 Flat 索引，适用于小规模的向量检索和精确检索。IndexIVFFlat：基于倒排索引（Inverted File）的 Flat 索引，适用于大规模的向量检索和近似检索。IndexIVFPQ：基于倒排索引和 Product Quantization 的索引，适用于大规模的向量检索和高效的近似检索。eg<span class="token punctuation">:</span><span class="token keyword">import</span> faissd <span class="token operator">=</span> <span class="token number">128</span>  <span class="token comment"># 向量维度</span>index <span class="token operator">=</span> faiss<span class="token punctuation">.</span>IndexFlatL2<span class="token punctuation">(</span>d<span class="token punctuation">)</span>    在上面的代码中，我们首先定义了向量的维度 d，然后使用 faiss<span class="token punctuation">.</span>IndexFlatL2 类创建了一个基于 L2 距离度量的 Flat 索引，并将其赋值给变量 index。这个索引对象可以用来存储向量和进行精确的向量检索。<span class="token comment">###</span><span class="token comment">###方法</span><span class="token keyword">def</span> <span class="token function">add_texts</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        texts<span class="token punctuation">:</span> Iterable<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        metadatas<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        ids<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    向索引中添加文本数据。    :param texts: 一个包含多个文本的可迭代对象，每个元素表示一个文本。    :param metadatas: 一个可选的列表，表示每个文本的元数据。每个元素是一个字典，包含文本的其它属性信息。    :param ids: 一个可选的列表，表示每个文本的 ID。如果不提供，则默认为 0, 1, 2, ...    :param kwargs: 其它可选参数，用于控制文本处理和特征提取的过程。    :return: 一个包含每个文本的 ID 的列表。    """</span>    生成向量的方式：embeddings <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>embedding_function<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> texts<span class="token punctuation">]</span>   <span class="token comment">#预训练的模型，用的Transformer</span>    vector <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>                <span class="token comment">###</span><span class="token keyword">def</span> <span class="token function">add_embeddings</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        text_embeddings<span class="token punctuation">:</span> Iterable<span class="token punctuation">[</span>Tuple<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        metadatas<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        ids<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    向索引中添加文本特征向量数据。    :param text_embeddings: 一个包含多个文本特征向量的可迭代对象，每个元素是一个元组 (text, embedding)，表示一个文本和其对应的特征向量。    :param metadatas: 一个可选的列表，表示每个文本的元数据。每个元素是一个字典，包含文本的其它属性信息。    :param ids: 一个可选的列表，表示每个文本的 ID。如果不提供，则默认为 0, 1, 2, ...    :param kwargs: 其它可选参数，用于控制特征处理和特征提取的过程。    :return: 一个包含每个文本的 ID 的列表。    """</span>                    <span class="token comment">###</span><span class="token keyword">def</span> <span class="token function">similarity_search_with_score_by_vector</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        embedding<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        <span class="token builtin">filter</span><span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        fetch_k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tuple<span class="token punctuation">[</span>Document<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    根据输入的特征向量进行相似度检索，并返回文本列表及其与输入向量的相似度得分。    :param embedding: 一个包含文本特征向量的列表，表示输入的特征向量。    :param k: 一个整数，表示需要检索的最近邻近似度数量。    :param filter: 一个可选的字典，表示需要过滤的条件。字典的键表示过滤条件，值表示过滤条件对应的值。    :param fetch_k: 一个整数，表示需要从索引中获取的文本数量。    :param kwargs: 其它可选参数，用于控制特征处理和特征提取的过程。    :return: 一个包含元组的列表，每个元组表示一个检索到的文本及其与输入向量的相似度得分。    """</span><span class="token operator">**</span><span class="token operator">*</span>注意<span class="token operator">**</span><span class="token operator">*</span>`k` 和 `fetch_k` 参数并不直接冲突，因为它们控制的是不同的内容。`k` 参数控制的是需要检索的最近邻近似度数量，而 `fetch_k` 参数控制的是需要从索引中获取的文本数量。在进行相似度检索时，首先会从索引中获取 `fetch_k` 个文本，然后从这些文本中选择与输入向量相似度最高的 `k` 个文本。例如，如果 `k<span class="token operator">=</span><span class="token number">4</span>`，`fetch_k<span class="token operator">=</span><span class="token number">20</span>`，则表示需要从索引中获取与输入向量相似度最高的 <span class="token number">20</span> 个文本，然后再从这 <span class="token number">20</span> 个文本中选择与输入向量相似度最高的 <span class="token number">4</span> 个文本。实际上，`fetch_k` 的取值可以比 `k` 大，这样可以保证在选择与输入向量相似度最高的 `k` 个文本时，有更多的文本可供选择，从而提高检索的准确性。但是，设置过大的 `fetch_k` 值可能会影响检索效率和内存消耗，需要根据具体情况进行调整。这个方法是对上面similarity_search_with_score_by_vector的封装。<span class="token keyword">def</span> <span class="token function">similarity_search_with_score</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        query<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>        k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        <span class="token builtin">filter</span><span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        fetch_k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tuple<span class="token punctuation">[</span>Document<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    根据输入的文本进行相似度检索，并返回文本列表及其与输入文本的相似度得分。    :param query: 一个字符串，表示输入的文本。    :param k: 一个整数，表示需要检索的最近邻近似度数量。    :param filter: 一个可选的字典，表示需要过滤的条件。字典的键表示过滤条件，值表示过滤条件对应的值。    :param fetch_k: 一个整数，表示需要从索引中获取的文本数量。    :param kwargs: 其它可选参数，用于控制特征处理和特征提取的过程。    :return: 一个包含元组的列表，每个元组表示一个检索到的文本及其与输入文本的相似度得分。    """</span><span class="token builtin">filter</span> 参数是一个可选的字典，表示需要过滤的条件。字典的键表示过滤条件，值表示过滤条件对应的值。例如，可以使用 <span class="token builtin">filter</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'category'</span><span class="token punctuation">:</span> <span class="token string">'sports'</span><span class="token punctuation">}</span> 来过滤类别为 <span class="token string">'sports'</span> 的文本。<span class="token comment">#查询得分</span><span class="token keyword">for</span> doc<span class="token punctuation">,</span> score <span class="token keyword">in</span> results<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">.</span>text<span class="token punctuation">,</span> score<span class="token punctuation">)</span>                <span class="token comment">###</span><span class="token keyword">def</span> <span class="token function">similarity_search_by_vector</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        embedding<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        <span class="token builtin">filter</span><span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        fetch_k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token punctuation">:</span>    embedding：一个浮点数列表，表示查询向量的嵌入（embedding）。k：一个整数，表示要返回的最相似文档的数量。默认为 <span class="token number">4</span>。<span class="token builtin">filter</span>：一个字典，表示要过滤的文档属性。该字典的键值对表示要过滤的属性和其对应的值。默认   为 <span class="token boolean">None</span>，表示不进行过滤。fetch_k：一个整数，表示要从倒排索引中检索的文档数量。默认为 <span class="token number">20</span>。<span class="token operator">**</span>kwargs：一个可变关键字参数，表示其他参数        这个方法的实现依据similarity_search_with_score方法，不过只取出了前面部分<span class="token keyword">def</span> <span class="token function">similarity_search</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        query<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>        k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        <span class="token builtin">filter</span><span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        fetch_k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token punctuation">:</span>    query：一个字符串，表示查询的文本。k：一个整数，表示要返回的最相似文档的数量。默认为 <span class="token number">4</span>。<span class="token builtin">filter</span>：一个字典，表示要过滤的文档属性。该字典的键值对表示要过滤的属性和其对应的值。默认为 <span class="token boolean">None</span>，表示不进行过滤。fetch_k：一个整数，表示要从倒排索引中检索的文档数量。默认为 <span class="token number">20</span>。<span class="token operator">**</span>kwargs：一个可变关键字参数，表示其他参数。        <span class="token comment">###</span><span class="token keyword">def</span> <span class="token function">max_marginal_relevance_search_by_vector</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        embedding<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        fetch_k<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>        lambda_mult<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.5</span><span class="token punctuation">,</span>        <span class="token builtin">filter</span><span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token punctuation">:</span>    embedding：一个浮点数列表，表示查询向量的嵌入（embedding）。k：一个整数，表示要返回的最相似文档的数量。默认为 <span class="token number">4</span>。fetch_k：一个整数，表示要从倒排索引中检索的文档数量。默认为 <span class="token number">20</span>。lambda_mult：一个浮点数，表示查询向量和文档向量之间的权重。默认为 <span class="token number">0.5</span>。<span class="token builtin">filter</span>：一个字典，表示要过滤的文档属性。该字典的键值对表示要过滤的属性和其对应的值。默认为 <span class="token boolean">None</span>，表示不进行过滤。<span class="token operator">**</span>kwargs：一个可变关键字参数，表示其他参数。             <span class="token operator">**</span><span class="token operator">*</span>该函数的算法        当我们需要在一个文档集合中进行相似度搜索时，我们可以使用倒排索引等技术来快速定位与查询文本或向量最相似的文档。然而，仅仅根据相似度来排序文档列表并不一定能得到最好的结果。例如，在一个新闻搜索引擎中，如果用户查询 <span class="token string">"巴西足球"</span>，我们可能会得到很多相关的新闻文章，但这些文章之间可能会有很多重复的内容和观点，这样就不能满足用户的需求。为了解决这个问题，我们可以使用最大边际相关性 <span class="token punctuation">(</span>MMR<span class="token punctuation">)</span> 算法来对文档列表进行排序和筛选。MMR 算法通过将查询向量和已经选择的文档向量之间的相似度进行权衡，选择与查询向量最相关且彼此之间不太相似的文档。这样，我们可以得到一组有代表性、多样性和相关性的文档列表，从而更好地满足用户的需求。具体来说，在实现 `max_marginal_relevance_search_by_vector` 函数时，我们可以按照以下步骤进行：<span class="token number">1.</span> 使用倒排索引查找与查询向量最相似的文档，并将它们按相似度从高到低排列。<span class="token number">2.</span> 初始化一个文档列表 `selected_docs`，其中包含与查询向量最相似的前 `k` 个文档。<span class="token number">3.</span> 对于剩余的文档，计算它们与查询向量的相似度和它们与已选择文档的相似度，并计算它们的 MMR 值。MMR 值可以通过以下公式计算：   ````   MMR<span class="token punctuation">(</span>d<span class="token punctuation">)</span> <span class="token operator">=</span> λ × sim<span class="token punctuation">(</span>d<span class="token punctuation">,</span> q<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> λ<span class="token punctuation">)</span> × <span class="token builtin">max</span><span class="token punctuation">(</span>sim<span class="token punctuation">(</span>d<span class="token punctuation">,</span> d<span class="token string">') for d'</span> <span class="token keyword">in</span> selected_docs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>其中，`d` 表示当前文档，`q` 表示查询向量，`λ` 表示查询向量和文档向量之间的权重，`sim(d, q)` 表示文档 `d` 和查询向量 `q` 之间的相似度，`sim(d, d')` 表示文档 `d` 和已选择文档 `d'` 之间的相似度。</code></pre><p>   公式的意义是，选择与查询向量最相关的文档，并减少与已选择文档之间的相似度，从而得到与查询向量最相关且彼此之间不太相似的文档。<br>4. 将剩余文档按照 MMR 值从高到低排序，并选择前 <code>k</code> 个文档加入 <code>selected_docs</code> 中。<br>5. 返回 <code>selected_docs</code>。</p><p>需要注意的是，MMR 算法的性能和效果受到参数 <code>λ</code> 的影响。当 <code>λ</code> 的值较小时，算法更加注重文档之间的多样性，而当 <code>λ</code> 的值较大时，算法更加注重文档与查询的相似度。在实践中，可以根据具体的应用场景和用户需求来调整 <code>λ</code> 的值。</p><p>def max_marginal_relevance_search(<br>        self,<br>        query: str,<br>        k: int = 4,<br>        fetch_k: int = 20,<br>        lambda_mult: float = 0.5,<br>        filter: Optional[Dict[str, Any]] = None,<br>        **kwargs: Any,<br>    ) -&gt; List[Document]:</p><p>参数：</p><ul><li><code>query</code>：一个字符串，表示查询文本。</li><li><code>k</code>：一个整数，表示要返回的最相似文档的数量。默认为 4。</li><li><code>fetch_k</code>：一个整数，表示要从倒排索引中检索的文档数量。默认为 20。</li><li><code>lambda_mult</code>：一个浮点数，表示查询向量和文档向量之间的权重。默认为 0.5。</li><li><code>filter</code>：一个字典，表示要过滤的文档属性。该字典的键值对表示要过滤的属性和其对应的值。默认为 <code>None</code>，表示不进行过滤。</li><li><code>**kwargs</code>：一个可变关键字参数，表示其他参数。</li></ul><p>返回值：</p><ul><li>一个 <code>List[Document]</code> 类型的列表，表示与查询文本最相关的文档列表。该列表中的每个元素都是一个 <code>Document</code> 对象，包含与查询文本最相关的文档的信息，例如文本、得分、ID 等。</li></ul><p>具体来说，该函数的作用与 <code>max_marginal_relevance_search_by_vector</code> 函数类似，不同之处在于它接受一个查询文本而不是查询向量作为输入，并将查询文本转换为向量后调用 <code>max_marginal_relevance_search_by_vector</code> 函数来实现相似度搜索和检索。在函数内部，可以使用语言模型或词嵌入模型将查询文本转换为向量，然后将向量传递给 <code>max_marginal_relevance_search_by_vector</code> 函数进行后续处理。该函数通常用于在文档集合中进行相似度搜索和检索。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>def merge_from(self, target: FAISS) -&gt; None:</p><p>这是一个方法名为 merge_from 的函数，它定义在一个名为 FAISS 的对象中。这个函数的作用是将另一个 FAISS 对象合并进当前对象。</p><p>具体来说，当我们需要将两个 FAISS 对象合并成一个时，可以使用 merge_from 方法。该方法的参数 target 是一个 FAISS 对象，表示要合并进当前对象的目标对象。合并后，目标对象的文档将被添加到当前对象的文档存储器 (docstore) 中，并且目标对象的索引 (index) 将被合并到当前对象的索引中。<br>###</p><pre><code>                                                                           def __from(  cls,  texts: List[str],  embeddings: List[List[float]],  embedding: Embeddings,  metadatas: Optional[List[dict]] = None,  ids: Optional[List[str]] = None,  normalize_L2: bool = False,  **kwargs: Any,</code></pre><p>  ) -&gt; FAISS:<br>                                                                                 这是一个类方法，用于从文本和嵌入列表中构建一个 <code>FAISS</code> 对象。该函数的参数如下：</p><ul><li><code>cls</code>：类本身。</li><li><code>texts</code>：一个字符串列表，包含待索引的文本。</li><li><code>embeddings</code>：一个浮点数列表的列表，表示每个文本对应的嵌入向量。</li><li><code>embedding</code>：一个 <code>Embeddings</code> 对象，表示用于生成嵌入向量的嵌入器。</li><li><code>metadatas</code>：一个字典列表，包含每个文档的元数据。默认为 <code>None</code>。</li><li><code>ids</code>：一个字符串列表，表示每个文档的唯一标识符。默认为 <code>None</code>。</li><li><code>normalize_L2</code>：一个布尔值，表示是否对嵌入向量进行L2范数归一化。默认为 <code>False</code>。</li><li><code>**kwargs</code>：一个可变关键字参数，表示其他参数。</li></ul><p>返回值：一个 <code>FAISS</code> 对象，表示构建的索引。</p><p>该方法的作用是将文本列表和嵌入列表转换为 <code>FAISS</code> 对象，以进行相似度搜索和检索。在函数内部，可以使用 <code>embedding</code> 对象将文本转换为嵌入向量，然后将嵌入向量传递给 <code>FAISS</code> 对象进行索引和搜索。</p><p>具体而言，该函数首先创建一个 <code>FAISS</code> 对象，并将嵌入向量添加到索引中。如果指定了元数据和文档 ID，则将它们与嵌入向量一起添加到索引中。为了快速搜索，该方法会对嵌入向量进行 L2 范数归一化，这可以提高搜索效率和准确性。</p><p>最后，该方法返回创建的 <code>FAISS</code> 对象。你可以使用该对象执行相似度搜索和检索，并获取与查询文本最相关的文档列表。<br>                                                                               ###<br>def from_texts(<br>        cls,<br>        texts: List[str],<br>        embedding: Embeddings,<br>        metadatas: Optional[List[dict]] = None,<br>        ids: Optional[List[str]] = None,<br>        **kwargs: Any,<br>    ) -&gt; FAISS:<br>                                                                                  使用上一个方法的__from进行实现<br>                                                                               这是一个类方法，用于从文本列表中构建一个 <code>FAISS</code> 对象。该函数的参数如下：</p><ul><li><code>cls</code>：类本身。</li><li><code>texts</code>：一个字符串列表，包含待索引的文本。</li><li><code>embedding</code>：一个 <code>Embeddings</code> 对象，表示用于生成嵌入向量的嵌入器。</li><li><code>metadatas</code>：一个字典列表，包含每个文档的元数据。默认为 <code>None</code>。</li><li><code>ids</code>：一个字符串列表，表示每个文档的唯一标识符。默认为 <code>None</code>。</li><li><code>**kwargs</code>：一个可变关键字参数，表示其他参数。</li></ul><p>返回值：一个 <code>FAISS</code> 对象，表示构建的索引。</p><p>该方法的作用是将文本列表转换为 <code>FAISS</code> 对象，以进行相似度搜索和检索。在函数内部，可以使用 <code>embedding</code> 对象将文本转换为嵌入向量，然后将嵌入向量传递给 <code>FAISS</code> 对象进行索引和搜索。</p><p>具体而言，该函数首先使用 <code>embedding</code> 对象将文本列表转换为嵌入向量列表。然后，创建一个 <code>FAISS</code> 对象，并将嵌入向量添加到索引中。如果指定了元数据和文档 ID，则将它们与嵌入向量一起添加到索引中。为了快速搜索，该方法会对嵌入向量进行 L2 范数归一化，这可以提高搜索效率和准确性。</p><p>最后，该方法返回创建的 <code>FAISS</code> 对象。你可以使用该对象执行相似度搜索和检索，并获取与查询文本最相关的文档列表。</p><pre><code>                                                                           ###</code></pre><p>def from_embeddings(<br>        cls,<br>        text_embeddings: List[Tuple[str, List[float]]],<br>        embedding: Embeddings,<br>        metadatas: Optional[List[dict]] = None,<br>        ids: Optional[List[str]] = None,<br>        **kwargs: Any,<br>    ) -&gt; FAISS:                                                               这是一个类方法，用于从文本嵌入元组列表中构建一个 <code>FAISS</code> 对象。该函数的参数如下：</p><ul><li><code>cls</code>：类本身。</li><li><code>text_embeddings</code>：一个元组列表，包含每个文本的唯一标识符和对应的嵌入向量。</li><li><code>embedding</code>：一个 <code>Embeddings</code> 对象，表示用于生成嵌入向量的嵌入器。</li><li><code>metadatas</code>：一个字典列表，包含每个文档的元数据。默认为 <code>None</code>。</li><li><code>ids</code>：一个字符串列表，表示每个文档的唯一标识符。默认为 <code>None</code>。</li><li><code>**kwargs</code>：一个可变关键字参数，表示其他参数。</li></ul><p>返回值：一个 <code>FAISS</code> 对象，表示构建的索引。</p><p>该方法的作用是将文本嵌入元组列表转换为 <code>FAISS</code> 对象，以进行相似度搜索和检索。在函数内部，可以使用 <code>embedding</code> 对象将嵌入向量添加到 <code>FAISS</code> 对象的索引中。</p><p>具体而言，该函数首先创建一个 <code>FAISS</code> 对象，并将嵌入向量添加到索引中。如果指定了元数据和文档 ID，则将它们与嵌入向量一起添加到索引中。为了快速搜索，该方法会对嵌入向量进行 L2 范数归一化，这可以提高搜索效率和准确性。</p><p>最后，该方法返回创建的 <code>FAISS</code> 对象。你可以使用该对象执行相似度搜索和检索，并获取与查询文本最相关的文档列表。</p><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><pre><code>                                                                           def save_local(self, folder_path: str, index_name: str = "index") -&gt; None:</code></pre><p>这是一个实例方法，用于将 <code>FAISS</code> 对象保存到本地文件夹。该函数的参数如下：</p><ul><li><code>folder_path</code>：一个字符串，表示本地文件夹的路径，用于保存索引文件。</li><li><code>index_name</code>：一个字符串，表示索引文件的名称。默认为 <code>"index"</code>。</li></ul><p>该方法的作用是将 <code>FAISS</code> 对象保存到本地文件夹中，以便在以后的时间内进行加载和使用。在函数内部，该方法使用 <code>faiss.write_index</code> 函数将索引对象写入文件，并保存到指定的文件夹中。</p><p>具体而言，该方法首先检查文件夹是否存在，如果不存在，则创建一个新的文件夹。然后，使用 <code>faiss.write_index</code> 函数将索引对象写入文件，并将文件保存到指定的文件夹中。保存的索引文件可以在以后的时间内使用 <code>load_local</code> 方法加载。</p><p>最后，该方法返回 <code>None</code>。<br>                                                                               ###<br>def load_local(<br>        cls, folder_path: str, embeddings: Embeddings, index_name: str = “index”<br>    ) -&gt; FAISS:<br>                                                                               这是一个类方法，用于从本地文件夹中加载 <code>FAISS</code> 索引对象。该函数的参数如下：</p><ul><li><code>cls</code>：类本身。</li><li><code>folder_path</code>：一个字符串，表示本地文件夹的路径，用于加载索引文件。</li><li><code>embeddings</code>：一个 <code>Embeddings</code> 对象，表示用于生成嵌入向量的嵌入器。</li><li><code>index_name</code>：一个字符串，表示索引文件的名称。默认为 <code>"index"</code>。</li></ul><p>返回值：一个 <code>FAISS</code> 对象，表示已加载的索引。</p><p>该方法的作用是从本地文件夹中加载 <code>FAISS</code> 索引对象，并返回该对象以供使用。在函数内部，该方法使用 <code>faiss.read_index</code> 函数从文件中读取索引对象，并使用 <code>embeddings</code> 对象生成嵌入向量。然后，将嵌入向量添加到索引中，并返回创建的 <code>FAISS</code> 索引对象。</p><p>具体而言，该方法首先使用 <code>faiss.read_index</code> 函数从指定的文件夹中读取索引对象。然后，使用 <code>embeddings</code> 对象将存储在索引中的嵌入向量重新生成，并将它们添加到索引对象中。最后，该方法返回创建的 <code>FAISS</code> 对象，以供进行文本检索和相似度搜索。</p><p>需要注意的是，加载的索引对象必须与嵌入器对象 <code>embeddings</code> 兼容，即索引对象和嵌入器对象必须使用相同的嵌入策略和参数。否则，在进行文本检索和相似度搜索时可能会导致不准确的结果。</p><h3 id="def-similarity-search-with-relevance-scores"><a href="#def-similarity-search-with-relevance-scores" class="headerlink" title="def _similarity_search_with_relevance_scores("></a>def _similarity_search_with_relevance_scores(</h3><pre><code>    self,    query: str,    k: int = 4,    filter: Optional[Dict[str, Any]] = None,    fetch_k: int = 20,    **kwargs: Any,) -&gt; List[Tuple[Document, float]]:                                                                           </code></pre><p>这是一个私有方法，用于执行带有相关度得分的相似度搜索。该函数的参数如下：</p><ul><li><code>query</code>：一个字符串，表示查询文本。</li><li><code>k</code>：一个整数，表示每个查询的返回文档数。默认为 <code>4</code>。</li><li><code>filter</code>：一个字典，表示用于过滤搜索结果的过滤器。默认为 <code>None</code>。</li><li><code>fetch_k</code>：一个整数，表示在过滤之后要返回的文档数。默认为 <code>20</code>。</li><li><code>**kwargs</code>：一个可变关键字参数，表示其他参数。</li></ul><p>返回值：一个元组列表，表示查询文本与每个返回文档的相关度得分。</p><p>该方法的作用是执行带有相关度得分的相似度搜索，并返回与查询文本最相关的文档列表。在函数内部，该方法使用 <code>faiss.StandardGpuResources</code> 创建 GPU 资源，并使用 <code>embeddings</code> 对象将查询文本转换为嵌入向量。然后，使用 <code>faiss.Index.search</code> 函数执行相似度搜索，并根据相似度得分对搜索结果进行排序。最后，该方法返回查询文本与每个返回文档的相关度得分，并将它们封装为元组列表。</p><p>具体而言，该方法首先使用 <code>faiss.StandardGpuResources</code> 创建 GPU 资源，并使用 <code>embeddings</code> 对象将查询文本转换为嵌入向量。然后，使用 <code>faiss.Index.search</code> 函数执行相似度搜索，并获取与查询文本最相关的文档列表。在获取文档列表后，该方法对返回文档进行排序，并计算每个文档的相关度得分。如果指定了过滤器，则使用过滤器从搜索结果中过滤文档。最后，该方法将查询文本与每个返回文档的相关度得分封装为元组，并返回元组列表。</p><p>需要注意的是，该方法使用 GPU 资源执行相似度搜索，因此需要确保计算机上安装了支持 GPU 计算的 <code>faiss</code> 库，并且 GPU 资源可用。<br>   </p><pre class="line-numbers language-none"><code class="language-none">##### index定义是Any对象，我不知道它下一步调用的是哪个`````cores, indices = self.index.search(vector, k)` 是 `faiss` 库中 `Index` 类的一个方法，用于在索引中查找与给定向量最相似的 k 个向量。它返回两个数组：`cores` 和 `indices`。其中，`cores` 表示每个查询向量的相似度得分（即余弦相似度），`indices` 表示与每个查询向量最相似的 k 个向量的索引号。请确保您已经正确导入 `faiss` 库，并在代码中创建了 `Index` 对象并将其存储在 `self.index` 变量中。如果您的代码中仍然找不到 `search` 方法，请检查您的代码是否正确导入 `faiss` 库，并创建了正确的 `Index` 对象。`Any` 是 Python 中的一个类型注解，它表示可以是任何类型的对象。因此，当您定义一个类型为 `Any` 的变量时，它可以引用任何类型的对象，包括自定义类型、内置类型、模块、函数等等。在您的代码中，`index` 变量的类型为 `Any`，这意味着它可以引用任何类型的对象。如果您不确定它引用的是哪种类型的对象，可以尝试使用 `type` 函数来查看它的类型，例如：<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>print(type(index))<p></p><pre class="line-numbers language-none"><code class="language-none">这将输出 `index` 变量的类型。一旦您知道了 `index` 变量所引用的对象的类型，就可以查找该对象的文档或源代码，以了解它支持哪些方法和属性。如果该对象是 `faiss` 库中的 `Index` 类的实例，那么它应该支持 `search` 方法，用于在索引中查找与给定向量最相似的向量。````##### scores, indices = self.index.search(vector, k)#scores 表示每个查询向量的相似度得分（即余弦相似度），indices 表示与每个查询向量最相似的 k 个向量的索引号。for j,i in enumerate(indices[0]):这个地方为什么用indices[0]，他有什么含义````在 `faiss` 中，`search` 方法可以同时查询多个向量，并返回每个查询向量与数据库中其他向量的相似度得分和索引号。如果查询向量的数量为 `n`，则 `search` 方法返回的 `scores` 和 `indices` 是两个具有 `shape = (n, k)` 的数组，其中 `k` 表示每个查询向量返回的最相似向量的数量。例如，在以下代码中：```pythonscores, indices = self.index.search(queries, k)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果 <code>queries</code> 是一个 <code>m</code> 行 <code>d</code> 列的二维数组，表示 <code>m</code> 个查询向量，每个向量有 <code>d</code> 个维度，则 <code>scores</code> 和 <code>indices</code> 的 <code>shape</code> 分别为 <code>(m, k)</code> 和 <code>(m, k)</code>。</p><p>在该算法中，每次只查询一个向量，因此 <code>scores</code> 和 <code>indices</code> 都是一个一维数组，其中 <code>scores[0]</code> 表示查询向量与 k 个最相似向量的相似度得分，<code>indices[0]</code> 表示 k 个最相似向量在索引中的编号。</p><p>因此，在循环中只用到了 <code>indices[0]</code>，表示第一个查询向量的 k 个最相似向量在索引中的编号。至于 <code>indices[1]</code> 表示什么，由于本算法每次只查询一个向量，因此 <code>indices[1]</code> 没有实际意义，可以忽略。</p><p>暂时的理解</p><pre class="line-numbers language-none"><code class="language-none">LLM streaming reponse       STREAMING = True       这个加不加有什么区别```这个代码片段定义了一个名为 `STREAMING` 的变量，它的值为 `True`。这个变量的作用是控制是否启用流式响应（streaming response）。如果将 `STREAMING` 设置为 `False`，则表示禁用流式响应，这意味着服务端在处理完整个请求后才会向客户端发送响应。在这种情况下，客户端需要等待服务端处理完整个请求后才能开始处理响应，这可能会导致客户端等待时间过长，尤其是在处理大型请求或响应时。如果将 `STREAMING` 设置为 `True`，则表示启用流式响应，服务端会在处理请求期间不断向客户端发送响应。这种方式可以有效减少客户端等待的时间，同时也可以逐步返回响应结果，使得客户端可以更早地开始处理响应。但是，启用流式响应也会增加服务端的负担，因为服务端需要在处理请求时不断生成响应数据并发送给客户端。因此，是否启用流式响应取决于具体的应用场景和需求。如果请求和响应较小，可以禁用流式响应以简化实现；如果请求和响应较大，可以考虑启用流式响应以提高性能和用户体验。```##### @lru_cache(CACHED_VS_NUM)什么意思是```python@lru_cache(CACHED_VS_NUM)def load_vector_store(vs_path, embeddings):    return MyFAISS.load_local(vs_path, embeddings)`@lru_cache(CACHED_VS_NUM)` 是 Python 中的一个装饰器语法，它可以用来缓存函数的结果，以避免重复计算，提高程序的执行效率。`@lru_cache` 是 Python 标准库 `functools` 中提供的一个装饰器，它可以用来实现一个“最近最少使用”（Least Recently Used，LRU）的缓存机制。LRU 缓存会在缓存满时删除最近最少使用的缓存项，以保持缓存的最新和最常用状态。`CACHED_VS_NUM` 是一个参数，它用来指定缓存的最大容量，即缓存可以存储的最多的函数调用结果数量。当缓存已满时，新的函数调用会导致最近最少使用的缓存项被删除，以腾出空间给新的缓存项。因此，`@lru_cache(CACHED_VS_NUM)` 的意思就是使用 LRU 缓存机制来缓存函数的结果，并指定缓存的最大容量为 `CACHED_VS_NUM`。``````python如何减少模型的响应速度呢！response = {"query": query,            "result": resp,            "source_documents": related_docs_with_score}#这个是response的响应print(response["source_documents"])metadata={'source': 'pdf/计算机网络.pdf', 'score': 0})]{'query': '2', 'result': '','source_documents': [Document(page_content='AS 100 ', metadata={'source': 'pdf/计算机网络.pdf', 'score': 0})]}```##### if search_type == "similarity":      return self.similarity_search(query, **kwargs)   elif search_type == "mmr":        return self.max_marginal_relevance_search(query, **kwargs)这两个搜索哪个更好一点```这个问题的答案取决于具体的应用场景和需求。`similarity_search` 函数和 `max_marginal_relevance_search` 函数都是用于搜索最相似的向量，但是它们的实现方式略有不同，因此在不同的场景下可能会有不同的表现。`similarity_search` 函数使用余弦相似度来计算向量之间的相似度得分，并返回与查询向量最相似的前 k 个向量。这种方法简单直接，适用于大多数的基本搜索需求。如果您只需要找到与查询向量最相似的向量，那么 `similarity_search` 函数可能更适合您的需求。相比之下，`max_marginal_relevance_search` 函数使用最大边际相关性算法（MMR）来计算向量之间的相似度得分，并尝试最大化返回的向量之间的差异性。这种方法可以帮助您找到与查询向量不仅相似，而且尽可能不同的向量，从而提高搜索结果的多样性。如果您需要返回一组不仅相似而且多样化的向量，那么 `max_marginal_relevance_search` 函数可能更适合您的需求。需要注意的是，使用 `max_marginal_relevance_search` 函数可能会增加计算的复杂度和时间，因为它需要计算向量之间的相似度得分，并进行多次迭代以优化搜索结果。因此，在使用 `max_marginal_relevance_search` 函数时，需要权衡计算的复杂度和搜索结果的质量。```##### 如何查看一个模型有哪些层次<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>要查看一个模型的层次结构，可以使用PyTorch中的<code>named_parameters()</code>方法。这个方法可以返回一个生成器对象，用于迭代模型的所有参数及其对应的名称。通过遍历这个生成器对象，我们可以逐层查看模型的结构，找到每个层的名称以及相应的参数。</p><p>以下是一个查看模型层次结构的示例代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModel<span class="token comment"># 加载一个预训练的模型</span>model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span><span class="token comment"># 遍历模型的所有参数及其对应的名称</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 打印参数的名称和形状</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string"> - </span><span class="token interpolation"><span class="token punctuation">{</span>param<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个示例中，我们首先使用<code>AutoModel.from_pretrained()</code>方法加载了一个预训练的BERT模型。然后，我们使用<code>named_parameters()</code>方法遍历了这个模型的所有参数及其对应的名称，并打印了每个参数的名称和形状。通过观察这些输出，我们可以了解这个模型的层次结构，并查找每个层的名称以及相应的参数。</p><pre><code>##### 回调函数<pre class="line-numbers language-none"><code class="language-none">def change_chunk_conent(mode, label_conent, history):    conent = ""    if "chunk_conent" in label_conent:        conent = "搜索结果上下文关联"    elif "one_content_segmentation" in label_conent:  # 这里没用上，可以先留着        conent = "内容分段入库"    if mode:        return gr.update(visible=True), history + [[None, f"【已开启{conent}】"]]    else:        return gr.update(visible=False), history + [[None, f"【已关闭{conent}】"]]                chunk_conent.change(fn=change_chunk_conent,                                        inputs=[chunk_conent, gr.Textbox(value="chunk_conent", visible=False), chatbot],                                        outputs=[chunk_sizes, chatbot])                                                                                `change_chunk_conent` 函数是一个回调函数，用于响应 `chunk_content` 复选框的状态变化，并更新相关的组件状态。在 Gradio 库中，回调函数通常使用 `change()` 方法进行注册，以便在用户交互时自动调用。在这里，`chunk_conent.change(fn=change_chunk_conent, inputs=[chunk_conent, gr.Textbox(value="chunk_conent", visible=False), chatbot], outputs=[chunk_sizes, chatbot])` 方法注册了 `change_chunk_conent` 函数，并指定了该函数的输入和输出组件。具体来说，`inputs` 参数包括了 `chunk_conent` 复选框、一个隐藏的文本框（用于记录当前的 `chunk_content` 状态）和一个名为 `chatbot` 的聊天机器人组件，`outputs` 参数包括了一个名为 `chunk_sizes` 的下拉框和同样的 `chatbot` 聊天机器人组件。这些输入和输出组件都是在 `gr.Interface()` 中创建并添加到布局中的。当用户在 Web 界面中勾选或取消 `chunk_content` 复选框时，Gradio 库会自动调用 `change_chunk_conent` 函数，并传递当前 `chunk_content` 复选框的状态、隐藏的文本框的值和聊天机器人的历史记录等参数。`change_chunk_conent` 函数根据输入参数的值进行相应的处理，然后返回一个 `gr.update()` 对象，用于更新 `chunk_sizes` 和 `chatbot` 组件的显示状态和内容。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>##### 代码解释<pre class="line-numbers language-none"><code class="language-none">for file in files:    filename = os.path.split(file.name)[-1]    shutil.move(file.name, os.path.join(KB_ROOT_PATH, vs_id, "content", filename))    filelist.append(os.path.join(KB_ROOT_PATH, vs_id, "content", filename))            这段代码的作用是将一个文件列表中的文件从原来的位置移动到指定的目标目录，并将移动后的文件路径添加到一个文件路径列表中。具体来说，这段代码使用了Python标准库中的`os.path.split()`函数和`shutil.move()`函数。`os.path.split(file.name)`函数将文件路径`file.name`分割成两个部分：目录路径和文件名。`[-1]`索引表示返回分割后的结果中的文件名部分。然后，`shutil.move()`函数将文件从原来的位置移动到指定的目标目录。移动后的文件名不变，因此移动后的文件路径可以通过将目标目录路径和文件名拼接而得到。最后，`filelist.append()`函数将移动后的文件路径添加到一个文件路径列表中。总的来说，这段代码的作用是将一个文件列表中的文件移动到指定的目标目录，并将移动后的文件路径添加到一个文件路径列表中，以备后续使用。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">经过多次实验，结合速度，质量的考虑，文本查找量为1，文件扩展长度为150.{'query': '11', 'prompt': '已知信息：通过远射打进唯一进球， 尽管慢动作显示是打在瑞典队后卫腿上弹射入网， 但从过程到结果， 均显示了相同内容——“瑞典队的防守并非无懈可击”。 \u3000\u3000商瑞华让科研教练曹晓东等人对这场比赛进行精心剪辑， 尤其是瑞典队失球以及美国队形成有威胁射门的片段， 更是被放大进行动作分解，\n根据上述已知信息，简洁且专业地回答用户地问题。如果问题不清晰或无法从已知信息中得到答案，请回复"根据已知信息无法回答该问题，请提供足够的本地知识库信息"，切勿在答案中胡编乱造，切勿回答已知信息以外的问题，问题不明确的时，请回答问题不明确，答案请使用中文。问题是：11', 'result': '根据已知信息，可以得出以下结论：\n\n1. 进球是通过远射打进的，尽管慢动作显示是打在瑞典队后卫腿上弹射入网，但过程显示瑞典队的防守并非无懈可击。\n2. 这场比赛的精心剪辑包括对瑞典队失球以及美国队形成有威胁射门的片段进行动作分解。\n3. 商瑞华让科研教练曹晓东等人对这场比赛进行精心剪辑，以确保比赛结果符合预期，尤其是瑞典队的防守并非无懈可击。\n\n因此，可以得出结论：这场比赛的剪辑体现了商瑞华让科研教练曹晓东', 'source_documents': [Document(page_content='通过远射打进唯一进球， 尽管慢动作显示是打在瑞典队后卫腿上弹射入网， 但从过程到结果， 均显示了相同内容——“瑞典队的防守并非无懈可击”。 \u3000\u3000商瑞华让科研教练曹晓东等人对这场比赛进行精心剪辑， 尤其是瑞典队失球以及美国队形成有威胁射门的片段， 更是被放大进行动作分解，', metadata={'source': '1.txt', 'score': 983}, _lc_kwargs={'page_content': '通过远射打进唯一进球，', 'metadata': {'source': '1.txt', 'score': 983}})]}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> chatgpt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/07/05/top-down-lun-wen-fen-xi/"/>
      <url>/2023/07/05/top-down-lun-wen-fen-xi/</url>
      
        <content type="html"><![CDATA[<h5 id="MIXUP技术对模型的影响"><a href="#MIXUP技术对模型的影响" class="headerlink" title="MIXUP技术对模型的影响"></a>MIXUP技术对模型的影响</h5><pre class="line-numbers language-none"><code class="language-none">if mixup_active:        mixup_fn = Mixup(            mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,            prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,            label_smoothing=args.smoothing, num_classes=args.nb_classes)                        这段代码创建了一个名为"mixup_fn"的Mixup对象，如果"mixup_active"变量为True，则使用Mixup方法对输入数据进行数据增强，这是一种在训练期间增强模型鲁棒性的技术。具体来说，Mixup方法使用随机的线性组合将两个不同的输入样本混合在一起，从而生成一个新的样本。这个过程可以用以下公式表示：new_x = lam * x_i + (1 - lam) * x_jnew_y = lam * y_i + (1 - lam) * y_j其中，x_i和y_i是第一个输入样本的特征和标签，x_j和y_j是第二个输入样本的特征和标签，lam是一个介于[0, 1]之间的随机数，用于控制两个输入样本的混合程度。Mixup方法可以帮助模型学习到更鲁棒的特征表示，并可以降低过拟合的风险。在这段代码中，Mixup对象的参数由一系列命令行参数(args)控制，包括"mixup_alpha"、"cutmix_alpha"、"cutmix_minmax"、"prob"、"switch_prob"、"mode"、"label_smoothing"和"num_classes"。这些参数用于指定Mixup方法的具体实现方式，例如混合比例、剪切比例、标签平滑、混合模式等等。这个Mixup对象可以作为数据增强的一部分，用于对训练数据进行处理，从而提高模型的性能和鲁棒性。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="全连接层的作用是什么，数据维度会变化吗"><a href="#全连接层的作用是什么，数据维度会变化吗" class="headerlink" title="全连接层的作用是什么，数据维度会变化吗"></a>全连接层的作用是什么，数据维度会变化吗</h5><pre class="line-numbers language-none"><code class="language-none">全连接层是神经网络中常用的一种层，也称为线性层或密集连接层（Dense Layer）。其作用是将输入的特征向量进行线性变换，并添加偏置项，从而生成新的特征向量。具体来说，全连接层的输入为一个向量或矩阵，其中向量对应于单个样本的特征向量，矩阵对应于多个样本的特征向量。全连接层的输出也是一个向量或矩阵，其维度由全连接层中的神经元数量决定。在全连接层中，每个神经元与输入向量中的每个元素都有连接，因此可以捕捉输入向量中的所有特征信息，并生成新的特征表示。在神经网络中，全连接层通常用于将低级特征转换为高级特征，增强模型的表达能力和分类性能。例如，在图像分类任务中，全连接层可以将卷积层中提取的空间特征和通道特征进行组合，生成更具有判别力的特征表示，从而提高模型的分类准确率。在全连接层中，数据的维度通常会发生变化。具体来说，如果全连接层的输入是一个大小为(batch_size, input_dim)的矩阵，其中batch_size表示批次大小，input_dim表示输入特征向量的维度，而全连接层包含n个神经元，那么全连接层的输出将是一个大小为(batch_size, n)的矩阵，其中批次大小batch_size不变，而输出维度变为n。因此，全连接层的作用不仅是生成新的特征表示，同时也涉及到数据的维度变换。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="线性层代码分析"><a href="#线性层代码分析" class="headerlink" title="线性层代码分析"></a>线性层代码分析</h5><pre class="line-numbers language-none"><code class="language-none">class Decode_Block(nn.Module):    def __init__(self, inplanes):        super().__init__()        self.linear = nn.Linear(inplanes, inplanes, bias=False)        self.linear2 = nn.Linear(inplanes, inplanes, bias=False)    def forward(self, x):        x = self.linear(x)        out = self.linear2(x)        return x, out经过这个层，数据的维度会怎么变化经过Decode_Block模块的前向传播过程，输入张量x的维度不会发生变化。具体来说，输入张量x的维度为(inplanes,)，其中inplanes表示输入特征的维度，也是线性层的输入维度。在模块中，x首先通过self.linear线性层进行变换，其输出维度仍为(inplanes,)，表示对输入特征进行了线性变换。然后，x再次通过self.linear2线性层进行变换，其输出维度仍为(inplanes,)，表示对上一层的输出进行了另一次线性变换。总之，Decode_Block模块的作用是对输入特征进行两次线性变换，输出两个张量x和out，其维度均为(inplanes,)。在具体的Transformer decoder中，Decode_Block模块通常被多次堆叠在一起，以构成完整的解码器层。整个解码器层会接收来自编码器的特征向量作为输入，输出解码后的特征向量，其维度与输入特征向量相同。作用是什么Decode_Block模块是Transformer中decoder部分的基本模块之一，其作用是对编码器输出的特征向量进行解码，即将编码器的输出特征向量转换为目标序列或目标特征向量。具体来说，Decode_Block模块通过两个线性层对输入特征向量进行两次非线性变换，增强了特征向量的表达能力，使其更容易被模型所理解和利用。其中，第一个线性层可以看作是自注意力层，用于计算输入特征向量中不同位置之间的相似度，从而捕捉输入特征向量之间的关系。第二个线性层则可以看作是前馈神经网络，用于进一步映射输入特征向量的表示，从而更好地适应特定任务。在Transformer decoder中，通常会将多个Decode_Block模块堆叠在一起，以构成完整的解码器层。整个解码器层会接收来自编码器的特征向量作为输入，输出解码后的特征向量，其维度与输入特征向量相同，用于进行下游任务，如机器翻译、文本生成等。总之，Decode_Block模块是Transformer decoder的基本模块之一，其作用是对编码器输出的特征向量进行解码，增强特征向量的表达能力，从而更好地适应特定任务。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="TRANSFORMER代码分析"><a href="#TRANSFORMER代码分析" class="headerlink" title="TRANSFORMER代码分析"></a>TRANSFORMER代码分析</h5><pre class="line-numbers language-none"><code class="language-none">def __init__(            self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0., init_values=None,            drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):        super().__init__()        self.norm1 = norm_layer(dim)        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)        self.ls1 = LayerScale(dim, init_values=init_values) if init_values else nn.Identity()        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here        self.drop_path1 = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()        self.norm2 = norm_layer(dim)        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio), act_layer=act_layer, drop=drop)        self.ls2 = LayerScale(dim, init_values=init_values) if init_values else nn.Identity()        self.drop_path2 = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()它都有那些层，作用是什么这段代码中的类定义了一个基本的Transformer模块，其包括了多头注意力机制和前馈神经网络。具体来说，该模块包含以下几个层：- norm1: LayerNorm层，用于对输入特征向量进行归一化处理。- attn: Attention层，用于计算输入特征向量中不同位置之间的相似度，从而捕捉输入特征向量之间的关系。- ls1: LayerScale层，用于对Attention层的输出进行缩放，以避免梯度消失或爆炸。- drop_path1: DropPath层，用于实现随机深度剪枝，以提高模型的泛化能力。- norm2: LayerNorm层，用于对Attention层的输出进行归一化处理。- mlp: Mlp层，用于进一步映射Attention层的输出，从而更好地适应特定任务。- ls2: LayerScale层，用于对Mlp层的输出进行缩放，以避免梯度消失或爆炸。- drop_path2: DropPath层，用于实现随机深度剪枝，以提高模型的泛化能力。总之，这个Transformer模块包含了多个层，其中包括了自注意力层和前馈神经网络层，用于对输入特征向量进行表示学习和特征提取。这些层可以被堆叠在一起，以构成完整的Transformer编码器或解码器，用于处理序列数据、图像数据等任务。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="cos-sim-x3D-F-normalize-x-dim-x3D-1-F-normalize-self-prompt-None-…-None-dim-x3D-1-B-N-1"><a href="#cos-sim-x3D-F-normalize-x-dim-x3D-1-F-normalize-self-prompt-None-…-None-dim-x3D-1-B-N-1" class="headerlink" title="cos_sim = F.normalize(x, dim=-1) @ F.normalize(self.prompt[None, …, None], dim=1)  # B, N, 1"></a>cos_sim = F.normalize(x, dim=-1) @ F.normalize(self.prompt[None, …, None], dim=1)  # B, N, 1</h5><pre class="line-numbers language-none"><code class="language-none">这行代码的作用是计算输入张量 `x` 和模型参数 `self.prompt` 之间的余弦相似度。具体来说，它对输入张量 `x` 进行了 L2 归一化操作，然后将其与模型参数 `self.prompt` 进行 L2 归一化后的转置矩阵相乘，得到一个 B×N×1 的输出张量，其中 B 是输入张量的批次大小，N 是输入张量中每个向量的维度。在这里，`F.normalize(x, dim=-1)` 的作用是对输入张量 `x` 在最后一个维度上进行 L2 归一化，即对每个向量进行 L2 归一化，使得每个向量的 L2 范数为 1。这个操作可以使得输入张量中的向量更容易进行相似度计算，因为 L2 归一化后的向量在欧几里得空间中都位于单位球面上，距离可以转化为余弦相似度，更易于计算和比较。然后，`F.normalize(self.prompt[None, ..., None], dim=1)` 的作用是对模型参数 `self.prompt` 进行 L2 归一化，并将其扩展为一个 B×1×D 的张量，其中 D 是模型参数 `self.prompt` 的维度。这个操作可以使得模型参数 `self.prompt` 可以和每个输入向量进行相似度计算。最后，`@` 运算符表示矩阵乘法，它将 L2 归一化后的输入张量和转置后的 L2 归一化的模型参数进行矩阵乘法运算，得到一个 B×N×1 的张量，其中每个元素表示输入张量中的一个向量与模型参数之间的余弦相似度。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>人间观察</title>
      <link href="/2023/06/30/ren-jian-guan-cha/"/>
      <url>/2023/06/30/ren-jian-guan-cha/</url>
      
        <content type="html"><![CDATA[<h4 id="序"><a href="#序" class="headerlink" title="序"></a>序</h4><p>从前有一个小王子，<br>长得俊美又机灵。<br>他喜欢玩闹，不爱读书，<br>常常惹得皇帝生气。</p><p>皇帝是天上的玉帝，<br>统治着天宫和天地。<br>他看不惯小王子的行为，<br>决定将他贬到凡间。</p><p>小王子来到人间，<br>看到了许多新奇的事物。<br>他欣喜地玩耍，<br>忘记了回天上。</p><p>可是，人间的生活并不容易，<br>小王子开始感到孤独和困惑。<br>他开始思念天宫的美好，<br>希望能够回到天上。</p><p>于是，他开始努力读书学习，<br>认真思考人生的意义。<br>最终，他得到了玉帝的原谅，<br>回到了天宫，成为一名勤奋的仙子。</p><p>贪玩不务正业的人，<br>终究难以得到真正的幸福。<br>只有通过勤奋和努力，<br>才能获得成功和快乐。</p><h5 id="把每一天都当作最后一天，没有”明天”，永远没有"><a href="#把每一天都当作最后一天，没有”明天”，永远没有" class="headerlink" title="把每一天都当作最后一天，没有”明天”，永远没有"></a>把每一天都当作最后一天，没有”明天”，永远没有</h5><h5 id="6月30日，人间观察第7063日"><a href="#6月30日，人间观察第7063日" class="headerlink" title="6月30日，人间观察第7063日"></a>6月30日，人间观察第7063日</h5><pre class="line-numbers language-none"><code class="language-none">小王子凡胎肉体，虽无往日神力，然天资聪慧，风流倜傥，定做人间第一流。武汉大学计算机学院大楼  晴天今天主要做了智能客服的模型和知识数据库的创建阶段，大部分时间在计算机学院大楼度过。今天早上又起晚了，主要原因还是因为昨天晚上玩王者玩到两点。待会晚上晚一点要去跑步，然后开组会，进行下一项目的调研工作。目前科研存在的问题还是代码水平不足，不能依赖实验室里的大佬，自力更生，做大做强。今天晚上要在11点睡觉，睡前不要喝太多水。然后今天晚上继续做智能客服的项目。明天是2023年下半年第一天了，请拿出十足的勇气毅力，不枉此生！<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="7月1日，人间观察7064天"><a href="#7月1日，人间观察7064天" class="headerlink" title="7月1日，人间观察7064天"></a>7月1日，人间观察7064天</h5><pre class="line-numbers language-none"><code class="language-none">武汉大学信息学部国软C4  晴天闷热今天依然是在完成智能客服机器人的项目，但是在做项目的时候不够专心，工作不够认真，导致进度有些慢，主要在计算机学院大楼度过。主要是想要完成MOSS模型的创建和知识向量库的添加文件，删除和创建以及模型参数的设置，暂时未实现MOSS模型创建以及模型的参数设置。昨天晚上睡晚了，因为奖励（裂开了）。今天晚上没有跑步，明天一定要去健身房，加3km。今天晚上一定要11点睡觉，然后明天把目前的代码调试到没有bug，实现结合浏览器上网功能，并且开始看那个注意力机制。我想把我的项目做成前后端今天是2023年7月1日建党节，现在不年轻还何时年轻<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="7月2日，人间观察7065天"><a href="#7月2日，人间观察7065天" class="headerlink" title="7月2日，人间观察7065天"></a>7月2日，人间观察7065天</h5><pre class="line-numbers language-none"><code class="language-none">武汉大学文理学部总图书馆A2区 晴天闷热今天实训放假一天，今天主要对智能客服机器人做了调试，但是十分不认真。项目进度缓慢，调试了一些部分，发现查找设置查找数量为1，模型相应速度相对更快，句子填充长度为150，速度相对较快。效果还有待研究，今天晚上去了健身房，自己是真的菜。晚上看了疯狂原始人，活着不容易，优雅自由地活着需要极大的勇气。11点左右，突发想奖励，还好极力克制，11点左右就寝。明天要完成智能客服机器人的交流模式，以及前端对话模型，剩下几天要做调试工作。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="7月3日，人间观察7066天"><a href="#7月3日，人间观察7066天" class="headerlink" title="7月3日，人间观察7066天"></a>7月3日，人间观察7066天</h5><pre class="line-numbers language-none"><code class="language-none">武汉大学计算机学院大楼 晴天很热今天在做智能客服机器人的前端，进展不是很顺利，有些缓慢，总的来说是有些概念性的内容不了解。中午吃的手抓饼和可乐。晚上去踢球了，一个老黑把我嘴撞出血了，但问题不大，还是挺开心的，但是球技明显下降。体力肺活量明显跟不上，晚上是十一点睡觉的，但是喝水过多，睡眠质量不是很好。这两天要休息好，项目最关键的阶段了。踢完球回到寝室刷了2个小时手机。养好精力，体力，好好工作，加油！！<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="7月4日，人间观察7067天"><a href="#7月4日，人间观察7067天" class="headerlink" title="7月4日，人间观察7067天"></a>7月4日，人间观察7067天</h5><pre class="line-numbers language-none"><code class="language-none">武汉大学国软C4 晴天很热今天在做智能客服机器人的前端部分，目标不是很明确，导致做错。明天要加把劲，还要搞xm给的任务。。今天晚上奖励了自己，很后悔，青春不是在床上扭扭捏捏，而是要在自己擅长的领域发光发热！记住，把每一天都当作<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="7月5日，人间观察7068天"><a href="#7月5日，人间观察7068天" class="headerlink" title="7月5日，人间观察7068天"></a>7月5日，人间观察7068天</h5><pre class="line-numbers language-none"><code class="language-none">武汉大学计算机学院大楼 天气很热今天依然在做项目，但是还是工作不认真，不知道为什么，老是喜欢在最后阶段松懈，想一想，假如你两年前的6月8日没有摆烂，中午没有刷手机，理综考试没有发呆，英语考试没有分神，你现在会在哪里？没有如果，人生很难，但请努力。晚上的时候在教室里刷了一段时间手机，然后来了xm的任务😵<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="7月6日，人间观察7069天"><a href="#7月6日，人间观察7069天" class="headerlink" title="7月6日，人间观察7069天"></a>7月6日，人间观察7069天</h5><pre class="line-numbers language-none"><code class="language-none">武汉大学计算机学院大楼 天气很热今天是项目完工最后一天，今天上午完成了top down源码的分析，不是很难，能感受到自己的代码能力在提升。下午的时候跑通了一个柠檬的模型，在服务器上实现了微调，中午刷了木鱼的编辑部的故事。总的来说今天没有摆烂。明天项目验收，今天晚上要最后一次修改代码，完成项目无论如何，今天晚上必去健身房！！<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="7月7日-7月14，人间虚度"><a href="#7月7日-7月14，人间虚度" class="headerlink" title="7月7日~7月14，人间虚度"></a>7月7日~7月14，人间虚度</h5><h5 id="7月15日，人间观察7070天"><a href="#7月15日，人间观察7070天" class="headerlink" title="7月15日，人间观察7070天"></a>7月15日，人间观察7070天</h5><pre class="line-numbers language-none"><code class="language-none">今天开始做算法题，动一下脑子<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="7月16日，人间观察7071天"><a href="#7月16日，人间观察7071天" class="headerlink" title="7月16日，人间观察7071天"></a>7月16日，人间观察7071天</h5><pre class="line-numbers language-none"><code class="language-none">今天晚上去踢球了，平时浪费时间有点多。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="7月17日，人间观察7072天"><a href="#7月17日，人间观察7072天" class="headerlink" title="7月17日，人间观察7072天"></a>7月17日，人间观察7072天</h5><pre class="line-numbers language-none"><code class="language-none">今天完全是一副不在状态的样子，浪费了很多时间！！<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="7月21，人间观察7076天"><a href="#7月21，人间观察7076天" class="headerlink" title="7月21，人间观察7076天"></a>7月21，人间观察7076天</h5><pre class="line-numbers language-none"><code class="language-none">今天要完成top_down论文的改进，leetcode刷题，继续学习人工智能<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="7月24日，人间观察7079天"><a href="#7月24日，人间观察7079天" class="headerlink" title="7月24日，人间观察7079天"></a>7月24日，人间观察7079天</h5><pre class="line-numbers language-none"><code class="language-none">突然意识到自己已经忘记写很多天的日记了，最近要尽快完成计算机网络课程设计和操作系统课程设计！！！追求得到之日即其终止之时，寻觅的过程亦即失去的过程。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="7月26日，人间观察7081天"><a href="#7月26日，人间观察7081天" class="headerlink" title="7月26日，人间观察7081天"></a>7月26日，人间观察7081天</h5><pre class="line-numbers language-none"><code class="language-none">河南上蔡张龙午村今天打了一天的王者，有点疲惫，看到了别人真的十分优秀，自己的两年有些混了，很伤心。永远不要做对自己有害的事情！！一切都会好的一切都会好起来的！！！定个计划，晚上11点之前睡觉，早上6点起床，坚持一个月！！！7点半开始工作，中午午休半小时！<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一晌贪欢</title>
      <link href="/2023/06/23/yi-shang-tan-huan/"/>
      <url>/2023/06/23/yi-shang-tan-huan/</url>
      
        <content type="html"><![CDATA[<p>阴阳怪气：</p><ol><li>人生本就五颜六色，你却卡在了黄色和绿色。</li><li>癞蛤蟆沾点海水，真当自己是海鲜了。</li><li>多照照镜子，你就明白其中的原因了。</li><li>上帝往人间洒满智慧，唯独你打开了伞。</li><li>你一来，这一锅粥都不能要了。</li><li>其实做人挺有趣的，你不妨试一试。</li><li>小东西，长的挺随机的。</li></ol><p>执子之手，与子偕老：</p><p>顶级享受：</p><ol><li>高二那年，自己用微积分推导出了流体力学方程，后来查到已经被称作伯努利流体方程。那一瞬间与先贤齐肩的感觉，一直记到现在。</li><li>博士论文通过的那一瞬间，你要知道，你亲手推动了人类的前进，在这个方向上，你是人类历史上到达这里的第一人。</li></ol><p>鸡汤来喽:</p><ol><li><p>看似不起波澜的日复一日，一定会在某一天让你看到坚持的意义，穷则独善其身，达则兼济天下，没有谁的一生是一帆风顺的，起起伏伏跌跌撞撞才是常有的状态，再贵的东西除以365都会变得很便宜。写作文的时候要分开头、中间、结尾，人生也是，从出生入学、三十而立到老了入土为安，每一个人都想努力活成自己想要的样子，你能作茧自缚就能破茧成蝶，人生就是一场自我完善的修行，这一切的苦难和折磨都是对自己的磨练，曾经所有的哭泣和悲欢喜乐，都是塑造一个更加完美的自己。有句话是这样说的：太阳升起时事业和工作就要投身，太阳落下时就是自我完善复盘的时候。你要相信，所有的事与愿违和苦难都是未来惊喜的铺垫，无论你现在混成什么模样，都要相信自己前途无量，然后努力拼搏，千万别让温水煮了你的将军梦，人生就一次，别认输！</p></li><li><p>人在年轻的时候可以逃避很多东西，但在承担责任的那一刻，你就没有资格年轻了，工作你得有，家庭你得顾，孩子你得护，形象你得树。十年前，连多愁善感都要渲染的惊天动地，十年后，越痛越不动声色，越苦越保持沉默。与买桂花同载酒，终不似，少年游，时间磨去了年少轻狂，也渐渐沉淀了冷暖自知。去做和你年龄相匹配的事，这叫责任，也是一个人活着的价值。风景依旧在，人已非少年。</p></li><li><p>这些年你可能经历了人生的至暗时刻，也许满是心酸，也许疲惫不堪，也许很多遗憾。但请你找到一个目标，务必坚持下去，千百次的站起来。那些带着晨间的寂静，不眠的星光，孤军奋战的清醒。你若决定灿烂，那么山无遮，海无栏，光总会撒在你的身上。尽管眼下十分艰难，但日后这段经历，说不定会开花结果，我们终其一生，并不是为了满足所有人。只要你喜欢，每一秒都是豆蔻年华，我们不用活在他人的言语之下，外界的声音只是参考。山有顶峰，湖有彼岸。在人生漫漫长路中，万物皆有回转，当我们任务余味苦涩，请你相信一切皆有回甘。向未来张望的时光，也许孤独而漫长，努力过后回事晴朗，尽管走，走到灯火通明，走到春暖花开，走到苦尽甘来，我们终将成为更好地自己。在苦难的时候别忘记了，给自己点燃一盏名叫希望的灯，用尽全力，过完这平凡但不平庸的一生。</p></li><li><p>爱自己的方式有很多，给自己一点时间吧，好好的缓一缓，然后就好好爱自己，把期望降低，把依赖变少，我相信你一定会过的很好。你要活着自己的世界里，这短暂的一生要为自己而活，去经历去后悔去改变，不要被别人左右，勇敢的去尝试一切。想表白就表白，想发照片就发照片，想穿什么就穿什么，想做什么就做什么，干嘛非得活在别人的嘴里呢。活在自己的世界里，不也挺好的吗，总有一天，你会发现，能让你重新振作起来的人，只有你自己。所以千万不要再自卑和焦虑中，度过这一生，你要坦然地接受不完美的自己，勇敢的面对这个社会，说句实话，没有人会在意你，就像你没那么在意别人一样。你只需要大大方方地做自己就好了，毕竟我们都是人，终点都是面临死亡，所以在只有一次的人生里，我希望你无论几岁，都可以顺着自己的心意而活。</p></li></ol><p>理解：</p><ol><li>你委屈了可以摔门而出，妈妈委屈了只能做着家务，偷偷掉眼泪。 ——三毛</li><li>不要踩着父母的肩膀看过世间的繁华之后，嫌弃它们从未读书识字。 ——余华</li><li>你讨厌父亲的平庸，殊不知，他也曾是怀揣梦想的少年。</li><li>人生的三种境界：接受父母的平凡，接受自己的平凡，接受子女的平凡。 ——梁晓声</li><li>一个好的家庭不是多么殷实富有，而是一代一代的向上托举，让下一代更上一层楼，代代相承。</li><li>当有一天，生你养你的两个人都走了，这世间再也没有人真心地疼你了，也没有人在意你过的好不好。父母在，人生上有来往，父母去，人生只剩归途。  ——丰子恺</li><li>此生最大地遗憾，在父母本该享福地年纪，我们依旧是个不成器的样子，依旧是他们的负担和最放不下的牵挂。</li></ol><h5 id="歇后语"><a href="#歇后语" class="headerlink" title="歇后语"></a>歇后语</h5><p>1.骑自行车去酒吧——该省省该花花</p><p>2.厕所里打地铺——离死不远了</p><p>3.小刀割屁股——开了眼了</p><p>4.皮裤套棉裤，必定有缘故</p><p>5.驴——光屁股拉磨，转着圈丢人</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
